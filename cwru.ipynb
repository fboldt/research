{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cwru.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/fboldt/research/blob/master/cwru.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Con6WhcSFxxm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CWRU files location"
      ]
    },
    {
      "metadata": {
        "id": "uSt7Dc1-nzQn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "aquisitions = {}\n",
        "# Normal\n",
        "aquisitions[\"Normal_0\"] = \"97.mat\"\n",
        "aquisitions[\"Normal_1\"] = \"98.mat\"\n",
        "aquisitions[\"Normal_2\"] = \"99.mat\"\n",
        "aquisitions[\"Normal_3\"] = \"100.mat\"\n",
        "# DE Inner Race 0.007 inches\n",
        "aquisitions[\"DEIR007_0\"] = \"105.mat\"\n",
        "aquisitions[\"DEIR007_1\"] = \"106.mat\"\n",
        "aquisitions[\"DEIR007_2\"] = \"107.mat\"\n",
        "aquisitions[\"DEIR007_3\"] = \"108.mat\"\n",
        "# DE Inner Race 0.014 inches\n",
        "aquisitions[\"DEIR014_0\"] = \"169.mat\"\n",
        "aquisitions[\"DEIR014_1\"] = \"170.mat\"\n",
        "aquisitions[\"DEIR014_2\"] = \"171.mat\"\n",
        "aquisitions[\"DEIR014_3\"] = \"172.mat\"\n",
        "# DE Inner Race 0.021 inches\n",
        "aquisitions[\"DEIR021_0\"] = \"209.mat\"\n",
        "aquisitions[\"DEIR021_1\"] = \"210.mat\"\n",
        "aquisitions[\"DEIR021_2\"] = \"211.mat\"\n",
        "aquisitions[\"DEIR021_3\"] = \"212.mat\"\n",
        "# DE Ball 0.007 inches\n",
        "aquisitions[\"DEB007_0\"] = \"118.mat\"\n",
        "aquisitions[\"DEB007_1\"] = \"119.mat\"\n",
        "aquisitions[\"DEB007_2\"] = \"120.mat\"\n",
        "aquisitions[\"DEB007_3\"] = \"121.mat\"\n",
        "# DE Ball 0.014 inches\n",
        "aquisitions[\"DEB014_0\"] = \"185.mat\"\n",
        "aquisitions[\"DEB014_1\"] = \"186.mat\"\n",
        "aquisitions[\"DEB014_2\"] = \"187.mat\"\n",
        "aquisitions[\"DEB014_3\"] = \"188.mat\"\n",
        "# DE Ball 0.021 inches\n",
        "aquisitions[\"DEB021_0\"] = \"222.mat\"\n",
        "aquisitions[\"DEB021_1\"] = \"223.mat\"\n",
        "aquisitions[\"DEB021_2\"] = \"224.mat\"\n",
        "aquisitions[\"DEB021_3\"] = \"225.mat\"\n",
        "# DE Outer race 0.007 inches centered @6:00\n",
        "aquisitions[\"DEOR007@6_0\"] = \"130.mat\"\n",
        "aquisitions[\"DEOR007@6_1\"] = \"131.mat\"\n",
        "aquisitions[\"DEOR007@6_2\"] = \"132.mat\"\n",
        "aquisitions[\"DEOR007@6_3\"] = \"133.mat\"\n",
        "# DE Outer race 0.014 inches centered @6:00\n",
        "aquisitions[\"DEOR014@6_0\"] = \"197.mat\"\n",
        "aquisitions[\"DEOR014@6_1\"] = \"198.mat\"\n",
        "aquisitions[\"DEOR014@6_2\"] = \"199.mat\"\n",
        "aquisitions[\"DEOR014@6_3\"] = \"200.mat\"\n",
        "# DE Outer race 0.021 inches centered @6:00\n",
        "aquisitions[\"DEOR021@6_0\"] = \"234.mat\"\n",
        "aquisitions[\"DEOR021@6_1\"] = \"235.mat\"\n",
        "aquisitions[\"DEOR021@6_2\"] = \"236.mat\"\n",
        "aquisitions[\"DEOR021@6_3\"] = \"237.mat\"\n",
        "# DE Outer race 0.007 inches centered @3:00\n",
        "aquisitions[\"DEOR007@3_0\"] = \"144.mat\"\n",
        "aquisitions[\"DEOR007@3_1\"] = \"145.mat\"\n",
        "aquisitions[\"DEOR007@3_2\"] = \"146.mat\"\n",
        "aquisitions[\"DEOR007@3_3\"] = \"147.mat\"\n",
        "# DE Outer race 0.021 inches centered @3:00\n",
        "aquisitions[\"DEOR021@3_0\"] = \"246.mat\"\n",
        "aquisitions[\"DEOR021@3_1\"] = \"247.mat\"\n",
        "aquisitions[\"DEOR021@3_2\"] = \"248.mat\"\n",
        "aquisitions[\"DEOR021@3_3\"] = \"249.mat\"\n",
        "# DE Outer race 0.007 inches centered @12:00\n",
        "aquisitions[\"DEOR007@12_0\"] = \"156.mat\"\n",
        "aquisitions[\"DEOR007@12_1\"] = \"158.mat\"\n",
        "aquisitions[\"DEOR007@12_2\"] = \"159.mat\"\n",
        "aquisitions[\"DEOR007@12_3\"] = \"160.mat\"\n",
        "# DE Outer race 0.021 inches centered @12:00\n",
        "aquisitions[\"DEOR021@12_0\"] = \"258.mat\"\n",
        "aquisitions[\"DEOR021@12_1\"] = \"259.mat\"\n",
        "aquisitions[\"DEOR021@12_2\"] = \"260.mat\"\n",
        "aquisitions[\"DEOR021@12_3\"] = \"261.mat\"\n",
        "# FE Inner Race 0.007 inches\n",
        "aquisitions[\"FEIR007_0\"] = \"278.mat\"\n",
        "aquisitions[\"FEIR007_1\"] = \"279.mat\"\n",
        "aquisitions[\"FEIR007_2\"] = \"280.mat\"\n",
        "aquisitions[\"FEIR007_3\"] = \"281.mat\"\n",
        "# FE Inner Race 0.014 inches\n",
        "aquisitions[\"FEIR014_0\"] = \"274.mat\"\n",
        "aquisitions[\"FEIR014_1\"] = \"275.mat\"\n",
        "aquisitions[\"FEIR014_2\"] = \"276.mat\"\n",
        "aquisitions[\"FEIR014_3\"] = \"277.mat\"\n",
        "# FE Inner Race 0.021 inches\n",
        "aquisitions[\"FEIR021_0\"] = \"270.mat\"\n",
        "aquisitions[\"FEIR021_1\"] = \"271.mat\"\n",
        "aquisitions[\"FEIR021_2\"] = \"272.mat\"\n",
        "aquisitions[\"FEIR021_3\"] = \"273.mat\"\n",
        "# FE Ball 0.007 inches\n",
        "aquisitions[\"FEB007_0\"] = \"282.mat\"\n",
        "aquisitions[\"FEB007_1\"] = \"283.mat\"\n",
        "aquisitions[\"FEB007_2\"] = \"284.mat\"\n",
        "aquisitions[\"FEB007_3\"] = \"285.mat\"\n",
        "# FE Ball 0.014 inches\n",
        "aquisitions[\"FEB014_0\"] = \"286.mat\"\n",
        "aquisitions[\"FEB014_1\"] = \"287.mat\"\n",
        "aquisitions[\"FEB014_2\"] = \"288.mat\"\n",
        "aquisitions[\"FEB014_3\"] = \"289.mat\"\n",
        "# FE Ball 0.021 inches\n",
        "aquisitions[\"FEB021_0\"] = \"290.mat\"\n",
        "aquisitions[\"FEB021_1\"] = \"291.mat\"\n",
        "aquisitions[\"FEB021_2\"] = \"292.mat\"\n",
        "aquisitions[\"FEB021_3\"] = \"293.mat\"\n",
        "# FE Outer race 0.007 inches centered @6:00\n",
        "aquisitions[\"FEOR007@6_0\"] = \"294.mat\"\n",
        "aquisitions[\"FEOR007@6_1\"] = \"295.mat\"\n",
        "aquisitions[\"FEOR007@6_2\"] = \"296.mat\"\n",
        "aquisitions[\"FEOR007@6_3\"] = \"297.mat\"\n",
        "# FE Outer race 0.007 inches centered @3:00\n",
        "aquisitions[\"FEOR007@3_0\"] = \"298.mat\"\n",
        "aquisitions[\"FEOR007@3_1\"] = \"299.mat\"\n",
        "aquisitions[\"FEOR007@3_2\"] = \"300.mat\"\n",
        "aquisitions[\"FEOR007@3_3\"] = \"301.mat\"\n",
        "# FE Outer race 0.014 inches centered @3:00\n",
        "aquisitions[\"FEOR014@3_0\"] = \"310.mat\"\n",
        "aquisitions[\"FEOR014@3_1\"] = \"309.mat\"\n",
        "aquisitions[\"FEOR014@3_2\"] = \"311.mat\"\n",
        "aquisitions[\"FEOR014@3_3\"] = \"312.mat\"\n",
        "# FE Outer race 0.007 inches centered @12:00\n",
        "aquisitions[\"FEOR007@12_0\"] = \"302.mat\"\n",
        "aquisitions[\"FEOR007@12_1\"] = \"305.mat\"\n",
        "aquisitions[\"FEOR007@12_2\"] = \"306.mat\"\n",
        "aquisitions[\"FEOR007@12_3\"] = \"307.mat\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R_4WiLNSyrMB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generate a dictionary linking the labels with values to keep consistence"
      ]
    },
    {
      "metadata": {
        "id": "zHDI4LWbyoP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_labels_dict(aquisitions):\n",
        "  labels_dict = {}\n",
        "  value = 0\n",
        "  for key in aquisitions.keys():\n",
        "    label = key.split('_')[0]\n",
        "    if not label in labels_dict:\n",
        "      labels_dict[label] = value\n",
        "      value += 1\n",
        "  return labels_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Rz0cKigF7q6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert Matlab file into tensors"
      ]
    },
    {
      "metadata": {
        "id": "2tn5IFqkCHQx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "\n",
        "def aquisition2tensor(file_name, sample_size=512):\n",
        "  print(file_name, end=' ')\n",
        "  matlab_file = scipy.io.loadmat(file_name)\n",
        "  DE_time = [key for key in matlab_file if key.endswith(\"DE_time\")][0] #Find the DRIVE END aquisition key name\n",
        "  FE_time = [key for key in matlab_file if key.endswith(\"FE_time\")][0] #Find the FAN END aquisition key name\n",
        "  signal_begin = 0\n",
        "  aquisition_size = max(len(matlab_file[DE_time]),len(matlab_file[FE_time]))\n",
        "  DE_samples = []\n",
        "  FE_samples = []\n",
        "  while signal_begin + sample_size < aquisition_size:\n",
        "    DE_samples.append([item for sublist in matlab_file[DE_time][signal_begin:signal_begin+sample_size] for item in sublist])\n",
        "    FE_samples.append([item for sublist in matlab_file[FE_time][signal_begin:signal_begin+sample_size] for item in sublist])\n",
        "    signal_begin += sample_size\n",
        "  sample_tensor = np.stack([DE_samples,FE_samples],axis=2).astype('float32')\n",
        "  return sample_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x-G4gjyuvA7a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Extract datasets from aquisitions"
      ]
    },
    {
      "metadata": {
        "id": "YC4rhGwWMKT7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def concatenate_datasets(xd,yd,xo,yo):\n",
        "  if xd is None or yd is None:\n",
        "    xd = xo\n",
        "    yd = yo\n",
        "  else:\n",
        "    xd = np.concatenate((xd,xo))\n",
        "    yd = np.concatenate((yd,yo))\n",
        "  return xd,yd\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "def aquisitions_from_load(load, aquisitions, labels_dict,\n",
        "                          url=\"http://csegroups.case.edu/sites/default/files/bearingdatacenter/files/Datafiles/\"\n",
        "                         ):\n",
        "  samples = None\n",
        "  labels = None\n",
        "  for key in aquisitions:\n",
        "    if key.endswith(\"_\"+str(load)):\n",
        "      file_name = aquisitions[key]\n",
        "      urllib.request.urlretrieve(url+file_name, file_name)\n",
        "      aquisition_samples = aquisition2tensor(file_name)\n",
        "      aquisition_labels = np.ones(aquisition_samples.shape[0])*labels_dict[key.split('_')[0]]\n",
        "      samples,labels = concatenate_datasets(samples,labels,aquisition_samples,aquisition_labels)\n",
        "  print(load)\n",
        "  return samples,labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sfwmQa0RJMvb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Exrtract samples"
      ]
    },
    {
      "metadata": {
        "id": "HSASqQsHcgtj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "98e1a809-db61-4468-f83a-cd1b67f507b3"
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "labels_dict = get_labels_dict(aquisitions)\n",
        "print(labels_dict.keys())\n",
        "\n",
        "x0,y0 = aquisitions_from_load(0,aquisitions,labels_dict)\n",
        "x1,y1 = aquisitions_from_load(1,aquisitions,labels_dict)\n",
        "x2,y2 = aquisitions_from_load(2,aquisitions,labels_dict)\n",
        "x3,y3 = aquisitions_from_load(3,aquisitions,labels_dict)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['Normal', 'DEIR007', 'DEIR014', 'DEIR021', 'DEB007', 'DEB014', 'DEB021', 'DEOR007@6', 'DEOR014@6', 'DEOR021@6', 'DEOR007@3', 'DEOR021@3', 'DEOR007@12', 'DEOR021@12', 'FEIR007', 'FEIR014', 'FEIR021', 'FEB007', 'FEB014', 'FEB021', 'FEOR007@6', 'FEOR007@3', 'FEOR014@3', 'FEOR007@12'])\n",
            "97.mat 105.mat 169.mat 209.mat 118.mat 185.mat 222.mat 130.mat 197.mat 234.mat 144.mat 246.mat 156.mat 258.mat 278.mat 274.mat 270.mat 282.mat 286.mat 290.mat 294.mat 298.mat 310.mat 302.mat 0\n",
            "98.mat 106.mat 170.mat 210.mat 119.mat 186.mat 223.mat 131.mat 198.mat 235.mat 145.mat 247.mat 158.mat 259.mat 279.mat 275.mat 271.mat 283.mat 287.mat 291.mat 295.mat 299.mat 309.mat 305.mat 1\n",
            "99.mat 107.mat 171.mat 211.mat 120.mat 187.mat 224.mat 132.mat 199.mat 236.mat 146.mat 248.mat 159.mat 260.mat 280.mat 276.mat 272.mat 284.mat 288.mat 292.mat 296.mat 300.mat 311.mat 306.mat 2\n",
            "100.mat 108.mat 172.mat 212.mat 121.mat 188.mat 225.mat 133.mat 200.mat 237.mat 147.mat 249.mat 160.mat 261.mat 281.mat 277.mat 273.mat 285.mat 289.mat 293.mat 297.mat 301.mat 312.mat 307.mat 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_QgaHQFpBuDw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define f1-score macro averaged"
      ]
    },
    {
      "metadata": {
        "id": "HdRZ_4pJBzfk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "def f1_score_macro(y_true,y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hPLjBiao2GIK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define architecture model"
      ]
    },
    {
      "metadata": {
        "id": "fpcZrU4Mu9Vk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "b7c45be3-96d5-4ea1-d758-8d90a689dc82"
      },
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import Input\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "\n",
        "signal_input = Input(shape=(x0.shape[1],x0.shape[-1]), dtype='float32', name='signal')\n",
        "x = layers.Conv1D(64, 128, activation='relu')(signal_input)\n",
        "x = layers.Flatten()(x)\n",
        "condition_output = layers.Dense(len(labels_dict),activation='softmax',name='condition')(x)\n",
        "\n",
        "model = Model(signal_input, condition_output)\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "signal (InputLayer)          (None, 512, 2)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 385, 64)           16448     \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 24640)             0         \n",
            "_________________________________________________________________\n",
            "condition (Dense)            (None, 24)                591384    \n",
            "=================================================================\n",
            "Total params: 607,832\n",
            "Trainable params: 607,832\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y0xe9oYrW1lv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Perform experiments"
      ]
    },
    {
      "metadata": {
        "id": "UU0B-KF-W0eV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9098
        },
        "outputId": "a3e38d61-549d-4c3d-c3bb-98f22536bd91"
      },
      "cell_type": "code",
      "source": [
        "loads = list(range(4))\n",
        "nrounds = 5\n",
        "results = []\n",
        "for i,fold in enumerate(loads):\n",
        "  print(fold)\n",
        "  x_test, y_test = eval('x'+str(fold)),eval('y'+str(fold))\n",
        "  y_test = to_categorical(y_test)\n",
        "  x_train,y_train = None,None\n",
        "  for tfold in loads[:i]+loads[i+1:]:\n",
        "    x_train,y_train = concatenate_datasets(x_train,y_train,eval('x'+str(tfold)),eval('y'+str(tfold)))\n",
        "  y_train = to_categorical(y_train)\n",
        "  print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)\n",
        "  for round in range(nrounds):\n",
        "    print(round+1)\n",
        "    model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['accuracy',f1_score_macro])\n",
        "    history = model.fit(x_train,y_train,epochs=10,validation_split=0.33)\n",
        "    results.append(model.evaluate(x_test, y_test))\n",
        "    print(results[-1])\n",
        "  print(np.asarray(results[-nrounds:]))\n",
        "  print(np.mean(results[-nrounds:],axis=0),np.std(results[-nrounds:],axis=0))\n",
        "\n",
        "print(np.asarray(results))\n",
        "print(np.mean(results,axis=0),np.std(results,axis=0))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "(19208, 512, 2) (19208, 24) (5931, 512, 2) (5931, 24)\n",
            "1\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 5s 369us/step - loss: 0.0098 - acc: 0.8222 - f1_score_macro: 0.7993 - val_loss: 0.0055 - val_acc: 0.9150 - val_f1_score_macro: 0.9028\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 317us/step - loss: 3.4374e-04 - acc: 0.9955 - f1_score_macro: 0.9955 - val_loss: 0.0016 - val_acc: 0.9748 - val_f1_score_macro: 0.9733\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 320us/step - loss: 9.7022e-05 - acc: 0.9985 - f1_score_macro: 0.9985 - val_loss: 0.0012 - val_acc: 0.9814 - val_f1_score_macro: 0.9805\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 317us/step - loss: 5.6792e-05 - acc: 0.9992 - f1_score_macro: 0.9992 - val_loss: 8.7501e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9875\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 320us/step - loss: 3.0598e-05 - acc: 0.9995 - f1_score_macro: 0.9996 - val_loss: 7.6616e-04 - val_acc: 0.9871 - val_f1_score_macro: 0.9875\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 323us/step - loss: 3.6023e-05 - acc: 0.9995 - f1_score_macro: 0.9995 - val_loss: 3.9094e-04 - val_acc: 0.9945 - val_f1_score_macro: 0.9946\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 321us/step - loss: 3.0653e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 6.6143e-04 - val_acc: 0.9896 - val_f1_score_macro: 0.9895\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 320us/step - loss: 3.0351e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 5.1546e-04 - val_acc: 0.9924 - val_f1_score_macro: 0.9921\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 323us/step - loss: 3.0982e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 5.6862e-04 - val_acc: 0.9912 - val_f1_score_macro: 0.9910\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 320us/step - loss: 3.0763e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 5.6824e-04 - val_acc: 0.9905 - val_f1_score_macro: 0.9907\n",
            "5931/5931 [==============================] - 1s 152us/step\n",
            "[0.002139834537885679, 0.9688079581858035, 0.9683284622745356]\n",
            "2\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 4s 337us/step - loss: 3.0444e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 5.2304e-04 - val_acc: 0.9916 - val_f1_score_macro: 0.9918\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 323us/step - loss: 2.8584e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 3.7910e-04 - val_acc: 0.9940 - val_f1_score_macro: 0.9939\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 324us/step - loss: 3.0823e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 5.1187e-04 - val_acc: 0.9920 - val_f1_score_macro: 0.9919\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 323us/step - loss: 3.1648e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 2.3210e-04 - val_acc: 0.9965 - val_f1_score_macro: 0.9964\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 322us/step - loss: 3.2352e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 3.9179e-04 - val_acc: 0.9940 - val_f1_score_macro: 0.9938\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 321us/step - loss: 2.7094e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 2.3511e-04 - val_acc: 0.9964 - val_f1_score_macro: 0.9964\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 323us/step - loss: 2.9226e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 3.0347e-04 - val_acc: 0.9953 - val_f1_score_macro: 0.9953\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 324us/step - loss: 3.1143e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 3.0337e-04 - val_acc: 0.9954 - val_f1_score_macro: 0.9955\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 322us/step - loss: 3.0757e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 3.0242e-04 - val_acc: 0.9953 - val_f1_score_macro: 0.9952\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 324us/step - loss: 2.9639e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 5.5574e-04 - val_acc: 0.9910 - val_f1_score_macro: 0.9907\n",
            "5931/5931 [==============================] - 1s 156us/step\n",
            "[0.0029573232431432932, 0.9558253245658405, 0.9564584652623003]\n",
            "3\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 4s 344us/step - loss: 2.7284e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 3.5359e-04 - val_acc: 0.9945 - val_f1_score_macro: 0.9945\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 325us/step - loss: 3.1526e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 6.0023e-04 - val_acc: 0.9904 - val_f1_score_macro: 0.9899\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 324us/step - loss: 2.9801e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 9.1535e-04 - val_acc: 0.9849 - val_f1_score_macro: 0.9850\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 323us/step - loss: 3.1231e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 1.7433e-04 - val_acc: 0.9975 - val_f1_score_macro: 0.9976\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 321us/step - loss: 2.8919e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 2.3229e-04 - val_acc: 0.9957 - val_f1_score_macro: 0.9958\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 321us/step - loss: 3.0048e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 2.8768e-04 - val_acc: 0.9956 - val_f1_score_macro: 0.9955\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 324us/step - loss: 2.8278e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 3.4340e-04 - val_acc: 0.9950 - val_f1_score_macro: 0.9949\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 323us/step - loss: 2.9846e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 4.8116e-04 - val_acc: 0.9926 - val_f1_score_macro: 0.9925\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 320us/step - loss: 2.9228e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 2.8039e-04 - val_acc: 0.9956 - val_f1_score_macro: 0.9957\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 322us/step - loss: 2.7955e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 4.2608e-04 - val_acc: 0.9932 - val_f1_score_macro: 0.9933\n",
            "5931/5931 [==============================] - 1s 150us/step\n",
            "[0.00513451873889858, 0.9288484235373462, 0.9267277322436963]\n",
            "4\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 4s 340us/step - loss: 2.9178e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 2.9451e-04 - val_acc: 0.9959 - val_f1_score_macro: 0.9958\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 320us/step - loss: 3.0551e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 3.8931e-04 - val_acc: 0.9943 - val_f1_score_macro: 0.9942\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 325us/step - loss: 2.7131e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 9.0891e-04 - val_acc: 0.9841 - val_f1_score_macro: 0.9842\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 324us/step - loss: 3.0352e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 3.3185e-04 - val_acc: 0.9948 - val_f1_score_macro: 0.9949\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 325us/step - loss: 2.8180e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 3.8582e-04 - val_acc: 0.9940 - val_f1_score_macro: 0.9939\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 327us/step - loss: 2.9957e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 4.4162e-04 - val_acc: 0.9934 - val_f1_score_macro: 0.9934\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 323us/step - loss: 2.8982e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 4.3528e-04 - val_acc: 0.9932 - val_f1_score_macro: 0.9933\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 325us/step - loss: 3.2260e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 2.9248e-04 - val_acc: 0.9961 - val_f1_score_macro: 0.9961\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 2.4413e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 3.5541e-04 - val_acc: 0.9945 - val_f1_score_macro: 0.9947\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 327us/step - loss: 2.8845e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 3.0753e-04 - val_acc: 0.9959 - val_f1_score_macro: 0.9958\n",
            "5931/5931 [==============================] - 1s 160us/step\n",
            "[0.003707383061387888, 0.9445287472601585, 0.9439953521177954]\n",
            "5\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 5s 351us/step - loss: 2.9785e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 2.8291e-04 - val_acc: 0.9964 - val_f1_score_macro: 0.9962\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 347us/step - loss: 2.7542e-05 - acc: 0.9996 - f1_score_macro: 0.9997 - val_loss: 3.3302e-04 - val_acc: 0.9946 - val_f1_score_macro: 0.9945\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 5s 353us/step - loss: 2.8694e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 3.8979e-04 - val_acc: 0.9942 - val_f1_score_macro: 0.9942\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 348us/step - loss: 2.9488e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 2.2107e-04 - val_acc: 0.9975 - val_f1_score_macro: 0.9973\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 335us/step - loss: 3.0666e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 6.1194e-04 - val_acc: 0.9907 - val_f1_score_macro: 0.9907\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 3.1639e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 2.9307e-04 - val_acc: 0.9951 - val_f1_score_macro: 0.9949\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 2.9662e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 4.6254e-04 - val_acc: 0.9924 - val_f1_score_macro: 0.9925\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 2.9650e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 2.6560e-04 - val_acc: 0.9961 - val_f1_score_macro: 0.9961\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 3.1318e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 3.5360e-04 - val_acc: 0.9943 - val_f1_score_macro: 0.9945\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 2.6677e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 3.0150e-04 - val_acc: 0.9965 - val_f1_score_macro: 0.9963\n",
            "5931/5931 [==============================] - 1s 158us/step\n",
            "[0.0028697328321704817, 0.9575113808801214, 0.956831056218267]\n",
            "[[0.00213983 0.96880796 0.96832846]\n",
            " [0.00295732 0.95582532 0.95645847]\n",
            " [0.00513452 0.92884842 0.92672773]\n",
            " [0.00370738 0.94452875 0.94399535]\n",
            " [0.00286973 0.95751138 0.95683106]]\n",
            "[0.00336176 0.95110437 0.95046821] [0.00101596 0.01353012 0.01414826]\n",
            "1\n",
            "(18739, 512, 2) (18739, 24) (6400, 512, 2) (6400, 24)\n",
            "1\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 4s 349us/step - loss: 3.0859e-04 - acc: 0.9952 - f1_score_macro: 0.9952 - val_loss: 0.0013 - val_acc: 0.9804 - val_f1_score_macro: 0.9801\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 6.4928e-05 - acc: 0.9990 - f1_score_macro: 0.9991 - val_loss: 0.0012 - val_acc: 0.9816 - val_f1_score_macro: 0.9815\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 8.1160e-06 - acc: 0.9999 - f1_score_macro: 0.9999 - val_loss: 8.6341e-04 - val_acc: 0.9869 - val_f1_score_macro: 0.9867\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 3.6217e-07 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.6723e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9885\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 9.6495e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.4411e-04 - val_acc: 0.9863 - val_f1_score_macro: 0.9859\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 1.9953e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9112e-04 - val_acc: 0.9866 - val_f1_score_macro: 0.9865\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 1.4431e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.6960e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9854\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 325us/step - loss: 1.2096e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.8006e-04 - val_acc: 0.9871 - val_f1_score_macro: 0.9871\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 325us/step - loss: 1.0515e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0100e-04 - val_acc: 0.9864 - val_f1_score_macro: 0.9864\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 9.1541e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.7793e-04 - val_acc: 0.9871 - val_f1_score_macro: 0.9871\n",
            "6400/6400 [==============================] - 1s 156us/step\n",
            "[6.439069120022615e-05, 0.99890625, 0.9989831340312958]\n",
            "2\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 4s 357us/step - loss: 8.4111e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.4981e-04 - val_acc: 0.9875 - val_f1_score_macro: 0.9874\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 7.5139e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.2841e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 7.0393e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.8341e-04 - val_acc: 0.9871 - val_f1_score_macro: 0.9871\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 6.5462e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9124e-04 - val_acc: 0.9866 - val_f1_score_macro: 0.9866\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 6.0470e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.6152e-04 - val_acc: 0.9874 - val_f1_score_macro: 0.9874\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 5.6938e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.4861e-04 - val_acc: 0.9877 - val_f1_score_macro: 0.9876\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 5.3830e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.4576e-04 - val_acc: 0.9880 - val_f1_score_macro: 0.9879\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 5.0522e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1949e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9882\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 4.8106e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.4390e-04 - val_acc: 0.9880 - val_f1_score_macro: 0.9878\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 4.6038e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.6622e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9871\n",
            "6400/6400 [==============================] - 1s 156us/step\n",
            "[6.540991710835418e-05, 0.99890625, 0.9989732134342194]\n",
            "3\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 359us/step - loss: 4.3625e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.4101e-04 - val_acc: 0.9877 - val_f1_score_macro: 0.9880\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 4.1959e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1975e-04 - val_acc: 0.9884 - val_f1_score_macro: 0.9882\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 4.0552e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.3782e-04 - val_acc: 0.9880 - val_f1_score_macro: 0.9879\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 3.8224e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.9275e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9887\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 3.7409e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.0597e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9885\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 3.6128e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.2401e-04 - val_acc: 0.9884 - val_f1_score_macro: 0.9882\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 3.5350e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.4335e-04 - val_acc: 0.9884 - val_f1_score_macro: 0.9881\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 3.4287e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.2071e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9881\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 3.2856e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.3700e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9881\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 3.2167e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1417e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9882\n",
            "6400/6400 [==============================] - 1s 159us/step\n",
            "[6.516659570428373e-05, 0.99890625, 0.9990500983595848]\n",
            "4\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 4s 353us/step - loss: 3.1129e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.2168e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9882\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 335us/step - loss: 3.0533e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.0465e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9883\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 2.9479e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.0018e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9884\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 325us/step - loss: 2.8646e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.9623e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9886\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 324us/step - loss: 2.8188e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1879e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9883\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 2.7565e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.0326e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9885\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 2.6609e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1590e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9883\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 324us/step - loss: 2.6321e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.7982e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9887\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 2.5664e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.0973e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9884\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 325us/step - loss: 2.5151e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.9919e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9886\n",
            "6400/6400 [==============================] - 1s 155us/step\n",
            "[6.624353448879979e-05, 0.99890625, 0.9989732134342194]\n",
            "5\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 4s 354us/step - loss: 2.4588e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.9463e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9885\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 323us/step - loss: 2.3831e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.3105e-04 - val_acc: 0.9884 - val_f1_score_macro: 0.9881\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 324us/step - loss: 2.3364e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.9844e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9884\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 2.3277e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.8840e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9887\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 2.2682e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.9418e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9884\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 324us/step - loss: 2.2158e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.8992e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9886\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 2.1893e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.0084e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9884\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 325us/step - loss: 2.1448e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.9048e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9886\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 324us/step - loss: 2.1192e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.8743e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9886\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 320us/step - loss: 2.0599e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.8928e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9887\n",
            "6400/6400 [==============================] - 1s 155us/step\n",
            "[6.608888572032814e-05, 0.99890625, 0.9989831340312958]\n",
            "[[6.43906912e-05 9.98906250e-01 9.98983134e-01]\n",
            " [6.54099171e-05 9.98906250e-01 9.98973213e-01]\n",
            " [6.51665957e-05 9.98906250e-01 9.99050098e-01]\n",
            " [6.62435345e-05 9.98906250e-01 9.98973213e-01]\n",
            " [6.60888857e-05 9.98906250e-01 9.98983134e-01]]\n",
            "[6.54599248e-05 9.98906250e-01 9.98992559e-01] [6.69543009e-07 1.11022302e-16 2.91099289e-05]\n",
            "2\n",
            "(18736, 512, 2) (18736, 24) (6403, 512, 2) (6403, 24)\n",
            "1\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 4s 355us/step - loss: 3.9053e-05 - acc: 0.9995 - f1_score_macro: 0.9996 - val_loss: 0.0021 - val_acc: 0.9659 - val_f1_score_macro: 0.9656\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 326us/step - loss: 3.5237e-05 - acc: 0.9995 - f1_score_macro: 0.9995 - val_loss: 8.9354e-04 - val_acc: 0.9875 - val_f1_score_macro: 0.9875\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 326us/step - loss: 3.0675e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 9.5948e-04 - val_acc: 0.9863 - val_f1_score_macro: 0.9860\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 3.1727e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0016 - val_acc: 0.9748 - val_f1_score_macro: 0.9744\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 330us/step - loss: 2.9723e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0024 - val_acc: 0.9618 - val_f1_score_macro: 0.9616\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 323us/step - loss: 2.8337e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0013 - val_acc: 0.9788 - val_f1_score_macro: 0.9788\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 2.7702e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 8.6231e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9873\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 324us/step - loss: 2.7954e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0023 - val_acc: 0.9634 - val_f1_score_macro: 0.9628\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 324us/step - loss: 2.7745e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0011 - val_acc: 0.9827 - val_f1_score_macro: 0.9829\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 323us/step - loss: 2.9456e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0013 - val_acc: 0.9795 - val_f1_score_macro: 0.9792\n",
            "6403/6403 [==============================] - 1s 156us/step\n",
            "[5.3929635854020764e-08, 1.0, 1.0]\n",
            "2\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 4s 354us/step - loss: 3.2604e-05 - acc: 0.9995 - f1_score_macro: 0.9995 - val_loss: 0.0012 - val_acc: 0.9811 - val_f1_score_macro: 0.9812\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 2.8128e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0014 - val_acc: 0.9787 - val_f1_score_macro: 0.9784\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 324us/step - loss: 3.0530e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0019 - val_acc: 0.9696 - val_f1_score_macro: 0.9694\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 339us/step - loss: 2.8678e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0014 - val_acc: 0.9799 - val_f1_score_macro: 0.9792\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 347us/step - loss: 2.6340e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0022 - val_acc: 0.9651 - val_f1_score_macro: 0.9645\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 354us/step - loss: 2.8700e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0018 - val_acc: 0.9722 - val_f1_score_macro: 0.9722\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 351us/step - loss: 2.7164e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0024 - val_acc: 0.9615 - val_f1_score_macro: 0.9612\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 323us/step - loss: 2.9233e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0020 - val_acc: 0.9668 - val_f1_score_macro: 0.9670\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 324us/step - loss: 3.1148e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0020 - val_acc: 0.9675 - val_f1_score_macro: 0.9666\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 324us/step - loss: 2.6218e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0027 - val_acc: 0.9578 - val_f1_score_macro: 0.9575\n",
            "6403/6403 [==============================] - 1s 156us/step\n",
            "[2.944297101608079e-07, 1.0, 1.0]\n",
            "3\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 4s 353us/step - loss: 2.6852e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0020 - val_acc: 0.9683 - val_f1_score_macro: 0.9683\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 324us/step - loss: 2.9122e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0028 - val_acc: 0.9563 - val_f1_score_macro: 0.9562\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 324us/step - loss: 2.5444e-05 - acc: 0.9996 - f1_score_macro: 0.9997 - val_loss: 0.0020 - val_acc: 0.9691 - val_f1_score_macro: 0.9689\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 322us/step - loss: 2.8195e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0021 - val_acc: 0.9667 - val_f1_score_macro: 0.9667\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 2.4766e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0020 - val_acc: 0.9681 - val_f1_score_macro: 0.9679\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 324us/step - loss: 2.7961e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0019 - val_acc: 0.9701 - val_f1_score_macro: 0.9703\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 323us/step - loss: 2.7764e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0022 - val_acc: 0.9647 - val_f1_score_macro: 0.9648\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 323us/step - loss: 2.7687e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0021 - val_acc: 0.9667 - val_f1_score_macro: 0.9664\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 322us/step - loss: 2.8097e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0019 - val_acc: 0.9717 - val_f1_score_macro: 0.9715\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 2.6584e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0026 - val_acc: 0.9581 - val_f1_score_macro: 0.9584\n",
            "6403/6403 [==============================] - 1s 156us/step\n",
            "[1.54039047059426e-07, 1.0, 1.0]\n",
            "4\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 4s 358us/step - loss: 2.7780e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0021 - val_acc: 0.9680 - val_f1_score_macro: 0.9667\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 324us/step - loss: 2.7413e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0024 - val_acc: 0.9628 - val_f1_score_macro: 0.9628\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 326us/step - loss: 2.7277e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0024 - val_acc: 0.9607 - val_f1_score_macro: 0.9606\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 322us/step - loss: 2.9966e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0024 - val_acc: 0.9609 - val_f1_score_macro: 0.9609\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 321us/step - loss: 2.5275e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0018 - val_acc: 0.9704 - val_f1_score_macro: 0.9702\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 322us/step - loss: 2.7190e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0023 - val_acc: 0.9631 - val_f1_score_macro: 0.9634\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 326us/step - loss: 2.8555e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0023 - val_acc: 0.9630 - val_f1_score_macro: 0.9625\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 326us/step - loss: 2.7739e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0027 - val_acc: 0.9579 - val_f1_score_macro: 0.9575\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 322us/step - loss: 2.8074e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0021 - val_acc: 0.9660 - val_f1_score_macro: 0.9658\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 321us/step - loss: 2.5779e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0025 - val_acc: 0.9607 - val_f1_score_macro: 0.9606\n",
            "6403/6403 [==============================] - 1s 157us/step\n",
            "[9.135175654625627e-08, 1.0, 1.0]\n",
            "5\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 4s 356us/step - loss: 2.5171e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0022 - val_acc: 0.9657 - val_f1_score_macro: 0.9654\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 321us/step - loss: 2.6729e-05 - acc: 0.9996 - f1_score_macro: 0.9997 - val_loss: 0.0021 - val_acc: 0.9672 - val_f1_score_macro: 0.9671\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 321us/step - loss: 2.4768e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0026 - val_acc: 0.9597 - val_f1_score_macro: 0.9598\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 321us/step - loss: 2.7775e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0022 - val_acc: 0.9643 - val_f1_score_macro: 0.9644\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 321us/step - loss: 2.6574e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0023 - val_acc: 0.9626 - val_f1_score_macro: 0.9623\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 323us/step - loss: 2.6224e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0027 - val_acc: 0.9583 - val_f1_score_macro: 0.9576\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 322us/step - loss: 2.4188e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0026 - val_acc: 0.9575 - val_f1_score_macro: 0.9572\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 2.8036e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0029 - val_acc: 0.9550 - val_f1_score_macro: 0.9548\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 323us/step - loss: 2.4559e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0025 - val_acc: 0.9609 - val_f1_score_macro: 0.9606\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 324us/step - loss: 2.4973e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0029 - val_acc: 0.9525 - val_f1_score_macro: 0.9522\n",
            "6403/6403 [==============================] - 1s 155us/step\n",
            "[2.3899047413998334e-07, 1.0, 1.0]\n",
            "[[5.39296359e-08 1.00000000e+00 1.00000000e+00]\n",
            " [2.94429710e-07 1.00000000e+00 1.00000000e+00]\n",
            " [1.54039047e-07 1.00000000e+00 1.00000000e+00]\n",
            " [9.13517565e-08 1.00000000e+00 1.00000000e+00]\n",
            " [2.38990474e-07 1.00000000e+00 1.00000000e+00]]\n",
            "[1.66548125e-07 1.00000000e+00 1.00000000e+00] [8.95494151e-08 0.00000000e+00 0.00000000e+00]\n",
            "3\n",
            "(18734, 512, 2) (18734, 24) (6405, 512, 2) (6405, 24)\n",
            "1\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 362us/step - loss: 2.5632e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 3.5037e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 322us/step - loss: 2.4871e-05 - acc: 0.9996 - f1_score_macro: 0.9997 - val_loss: 7.1931e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 321us/step - loss: 2.4081e-05 - acc: 0.9996 - f1_score_macro: 0.9997 - val_loss: 4.6741e-06 - val_acc: 0.9998 - val_f1_score_macro: 0.9998\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 323us/step - loss: 2.8876e-05 - acc: 0.9995 - f1_score_macro: 0.9996 - val_loss: 1.1223e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 323us/step - loss: 2.8212e-05 - acc: 0.9995 - f1_score_macro: 0.9996 - val_loss: 3.0734e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 323us/step - loss: 2.3835e-05 - acc: 0.9996 - f1_score_macro: 0.9997 - val_loss: 2.5813e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 323us/step - loss: 2.3514e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 2.1710e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 1.9871e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 1.3898e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 322us/step - loss: 1.9305e-05 - acc: 0.9997 - f1_score_macro: 0.9997 - val_loss: 7.6720e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 1.8150e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 9.0714e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 156us/step\n",
            "[0.0023755481536881905, 0.9631537861046058, 0.9628093567609228]\n",
            "2\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 366us/step - loss: 2.0804e-05 - acc: 0.9997 - f1_score_macro: 0.9997 - val_loss: 2.4554e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 323us/step - loss: 2.0660e-05 - acc: 0.9997 - f1_score_macro: 0.9997 - val_loss: 3.8307e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 322us/step - loss: 2.0099e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 8.1766e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 324us/step - loss: 1.8746e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 9.5982e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 323us/step - loss: 1.9067e-05 - acc: 0.9997 - f1_score_macro: 0.9997 - val_loss: 3.4092e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 322us/step - loss: 1.9675e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 3.0046e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 321us/step - loss: 1.8227e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 9.1434e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 323us/step - loss: 1.9045e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 4.8984e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 1.8079e-05 - acc: 0.9997 - f1_score_macro: 0.9997 - val_loss: 5.4581e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 323us/step - loss: 1.8468e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 7.6247e-06 - val_acc: 0.9998 - val_f1_score_macro: 0.9998\n",
            "6405/6405 [==============================] - 1s 155us/step\n",
            "[0.003619412103940666, 0.9458235753317721, 0.9457527762181492]\n",
            "3\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 365us/step - loss: 1.9702e-05 - acc: 0.9997 - f1_score_macro: 0.9997 - val_loss: 5.6589e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 323us/step - loss: 2.0057e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 4.7787e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 1.8366e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 8.4409e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 323us/step - loss: 1.8541e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 2.4015e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 323us/step - loss: 1.8997e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 8.1269e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 323us/step - loss: 1.8199e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 4.7949e-08 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 321us/step - loss: 1.9724e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 2.6844e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 321us/step - loss: 1.7799e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 1.0302e-06 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 321us/step - loss: 1.9235e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 9.1957e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 322us/step - loss: 1.9574e-05 - acc: 0.9997 - f1_score_macro: 0.9997 - val_loss: 2.1711e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 153us/step\n",
            "[0.0025031645035781293, 0.9606557377049181, 0.9603084041586525]\n",
            "4\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 365us/step - loss: 1.8856e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 1.3998e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 322us/step - loss: 1.8381e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 3.3126e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 322us/step - loss: 1.8805e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 3.2541e-06 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 322us/step - loss: 1.9169e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 2.0093e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 324us/step - loss: 1.7874e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 7.9644e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 322us/step - loss: 1.8030e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 1.3385e-06 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 334us/step - loss: 1.8407e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 1.0890e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 350us/step - loss: 1.8483e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 1.2002e-06 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 349us/step - loss: 1.7531e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 1.6748e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 352us/step - loss: 1.7539e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 4.5844e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 158us/step\n",
            "[0.0027931907418666355, 0.9562841530054644, 0.9560113829434802]\n",
            "5\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 367us/step - loss: 1.8146e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 1.7214e-07 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 324us/step - loss: 1.8765e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 2.5399e-06 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 321us/step - loss: 1.8324e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 2.3811e-06 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 322us/step - loss: 1.7963e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 1.5560e-06 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 323us/step - loss: 1.8252e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 3.5994e-06 - val_acc: 0.9998 - val_f1_score_macro: 0.9998\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 1.8607e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 2.4292e-06 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 322us/step - loss: 1.7684e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 8.7049e-06 - val_acc: 0.9998 - val_f1_score_macro: 0.9998\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 324us/step - loss: 1.7599e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 5.1959e-06 - val_acc: 0.9998 - val_f1_score_macro: 0.9998\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 322us/step - loss: 1.8105e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 5.1997e-06 - val_acc: 0.9998 - val_f1_score_macro: 0.9998\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 322us/step - loss: 1.8005e-05 - acc: 0.9997 - f1_score_macro: 0.9998 - val_loss: 6.9778e-06 - val_acc: 0.9998 - val_f1_score_macro: 0.9998\n",
            "6405/6405 [==============================] - 1s 154us/step\n",
            "[0.0022816765652087664, 0.9648711943793911, 0.9650280448443065]\n",
            "[[0.00237555 0.96315379 0.96280936]\n",
            " [0.00361941 0.94582358 0.94575278]\n",
            " [0.00250316 0.96065574 0.9603084 ]\n",
            " [0.00279319 0.95628415 0.95601138]\n",
            " [0.00228168 0.96487119 0.96502804]]\n",
            "[0.0027146  0.95815769 0.95798199] [0.00048414 0.00681048 0.00680881]\n",
            "[[2.13983454e-03 9.68807958e-01 9.68328462e-01]\n",
            " [2.95732324e-03 9.55825325e-01 9.56458465e-01]\n",
            " [5.13451874e-03 9.28848424e-01 9.26727732e-01]\n",
            " [3.70738306e-03 9.44528747e-01 9.43995352e-01]\n",
            " [2.86973283e-03 9.57511381e-01 9.56831056e-01]\n",
            " [6.43906912e-05 9.98906250e-01 9.98983134e-01]\n",
            " [6.54099171e-05 9.98906250e-01 9.98973213e-01]\n",
            " [6.51665957e-05 9.98906250e-01 9.99050098e-01]\n",
            " [6.62435345e-05 9.98906250e-01 9.98973213e-01]\n",
            " [6.60888857e-05 9.98906250e-01 9.98983134e-01]\n",
            " [5.39296359e-08 1.00000000e+00 1.00000000e+00]\n",
            " [2.94429710e-07 1.00000000e+00 1.00000000e+00]\n",
            " [1.54039047e-07 1.00000000e+00 1.00000000e+00]\n",
            " [9.13517565e-08 1.00000000e+00 1.00000000e+00]\n",
            " [2.38990474e-07 1.00000000e+00 1.00000000e+00]\n",
            " [2.37554815e-03 9.63153786e-01 9.62809357e-01]\n",
            " [3.61941210e-03 9.45823575e-01 9.45752776e-01]\n",
            " [2.50316450e-03 9.60655738e-01 9.60308404e-01]\n",
            " [2.79319074e-03 9.56284153e-01 9.56011383e-01]\n",
            " [2.28167657e-03 9.64871194e-01 9.65028045e-01]]\n",
            "[0.0015355  0.97704208 0.97686069] [0.00162098 0.02379044 0.02410783]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tv7O1HexF8Ct",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "np.savetxt(\"results.csv\", np.asarray(results), delimiter=\", \", newline=\"\\r\\n\")\n",
        "files.download('results.csv') \n",
        "np.savetxt(\"summary.csv\", np.asarray(np.asarray([np.mean(results,axis=0),np.std(results,axis=0)])), delimiter=\", \", newline=\"\\r\\n\")\n",
        "files.download('summary.csv') \n",
        "with open('model.txt','w') as fh:\n",
        "    model.summary(print_fn=lambda x: fh.write('#' + x + '\\r\\n'))\n",
        "    fh.write(str(model.get_config()))\n",
        "files.download('model.txt') "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}