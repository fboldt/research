{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cwru.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/fboldt/research/blob/master/cwru.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Con6WhcSFxxm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CWRU files location"
      ]
    },
    {
      "metadata": {
        "id": "uSt7Dc1-nzQn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "aquisitions = {}\n",
        "# Normal\n",
        "aquisitions[\"Normal_0\"] = \"97.mat\"\n",
        "aquisitions[\"Normal_1\"] = \"98.mat\"\n",
        "aquisitions[\"Normal_2\"] = \"99.mat\"\n",
        "aquisitions[\"Normal_3\"] = \"100.mat\"\n",
        "# DE Inner Race 0.007 inches\n",
        "aquisitions[\"DEIR007_0\"] = \"105.mat\"\n",
        "aquisitions[\"DEIR007_1\"] = \"106.mat\"\n",
        "aquisitions[\"DEIR007_2\"] = \"107.mat\"\n",
        "aquisitions[\"DEIR007_3\"] = \"108.mat\"\n",
        "# DE Inner Race 0.014 inches\n",
        "aquisitions[\"DEIR014_0\"] = \"169.mat\"\n",
        "aquisitions[\"DEIR014_1\"] = \"170.mat\"\n",
        "aquisitions[\"DEIR014_2\"] = \"171.mat\"\n",
        "aquisitions[\"DEIR014_3\"] = \"172.mat\"\n",
        "# DE Inner Race 0.021 inches\n",
        "aquisitions[\"DEIR021_0\"] = \"209.mat\"\n",
        "aquisitions[\"DEIR021_1\"] = \"210.mat\"\n",
        "aquisitions[\"DEIR021_2\"] = \"211.mat\"\n",
        "aquisitions[\"DEIR021_3\"] = \"212.mat\"\n",
        "# DE Ball 0.007 inches\n",
        "aquisitions[\"DEB007_0\"] = \"118.mat\"\n",
        "aquisitions[\"DEB007_1\"] = \"119.mat\"\n",
        "aquisitions[\"DEB007_2\"] = \"120.mat\"\n",
        "aquisitions[\"DEB007_3\"] = \"121.mat\"\n",
        "# DE Ball 0.014 inches\n",
        "aquisitions[\"DEB014_0\"] = \"185.mat\"\n",
        "aquisitions[\"DEB014_1\"] = \"186.mat\"\n",
        "aquisitions[\"DEB014_2\"] = \"187.mat\"\n",
        "aquisitions[\"DEB014_3\"] = \"188.mat\"\n",
        "# DE Ball 0.021 inches\n",
        "aquisitions[\"DEB021_0\"] = \"222.mat\"\n",
        "aquisitions[\"DEB021_1\"] = \"223.mat\"\n",
        "aquisitions[\"DEB021_2\"] = \"224.mat\"\n",
        "aquisitions[\"DEB021_3\"] = \"225.mat\"\n",
        "# DE Outer race 0.007 inches centered @6:00\n",
        "aquisitions[\"DEOR007@6_0\"] = \"130.mat\"\n",
        "aquisitions[\"DEOR007@6_1\"] = \"131.mat\"\n",
        "aquisitions[\"DEOR007@6_2\"] = \"132.mat\"\n",
        "aquisitions[\"DEOR007@6_3\"] = \"133.mat\"\n",
        "# DE Outer race 0.014 inches centered @6:00\n",
        "aquisitions[\"DEOR014@6_0\"] = \"197.mat\"\n",
        "aquisitions[\"DEOR014@6_1\"] = \"198.mat\"\n",
        "aquisitions[\"DEOR014@6_2\"] = \"199.mat\"\n",
        "aquisitions[\"DEOR014@6_3\"] = \"200.mat\"\n",
        "# DE Outer race 0.021 inches centered @6:00\n",
        "aquisitions[\"DEOR021@6_0\"] = \"234.mat\"\n",
        "aquisitions[\"DEOR021@6_1\"] = \"235.mat\"\n",
        "aquisitions[\"DEOR021@6_2\"] = \"236.mat\"\n",
        "aquisitions[\"DEOR021@6_3\"] = \"237.mat\"\n",
        "# DE Outer race 0.007 inches centered @3:00\n",
        "aquisitions[\"DEOR007@3_0\"] = \"144.mat\"\n",
        "aquisitions[\"DEOR007@3_1\"] = \"145.mat\"\n",
        "aquisitions[\"DEOR007@3_2\"] = \"146.mat\"\n",
        "aquisitions[\"DEOR007@3_3\"] = \"147.mat\"\n",
        "# DE Outer race 0.021 inches centered @3:00\n",
        "aquisitions[\"DEOR021@3_0\"] = \"246.mat\"\n",
        "aquisitions[\"DEOR021@3_1\"] = \"247.mat\"\n",
        "aquisitions[\"DEOR021@3_2\"] = \"248.mat\"\n",
        "aquisitions[\"DEOR021@3_3\"] = \"249.mat\"\n",
        "# DE Outer race 0.007 inches centered @12:00\n",
        "aquisitions[\"DEOR007@12_0\"] = \"156.mat\"\n",
        "aquisitions[\"DEOR007@12_1\"] = \"158.mat\"\n",
        "aquisitions[\"DEOR007@12_2\"] = \"159.mat\"\n",
        "aquisitions[\"DEOR007@12_3\"] = \"160.mat\"\n",
        "# DE Outer race 0.021 inches centered @12:00\n",
        "aquisitions[\"DEOR021@12_0\"] = \"258.mat\"\n",
        "aquisitions[\"DEOR021@12_1\"] = \"259.mat\"\n",
        "aquisitions[\"DEOR021@12_2\"] = \"260.mat\"\n",
        "aquisitions[\"DEOR021@12_3\"] = \"261.mat\"\n",
        "# FE Inner Race 0.007 inches\n",
        "aquisitions[\"FEIR007_0\"] = \"278.mat\"\n",
        "aquisitions[\"FEIR007_1\"] = \"279.mat\"\n",
        "aquisitions[\"FEIR007_2\"] = \"280.mat\"\n",
        "aquisitions[\"FEIR007_3\"] = \"281.mat\"\n",
        "# FE Inner Race 0.014 inches\n",
        "aquisitions[\"FEIR014_0\"] = \"274.mat\"\n",
        "aquisitions[\"FEIR014_1\"] = \"275.mat\"\n",
        "aquisitions[\"FEIR014_2\"] = \"276.mat\"\n",
        "aquisitions[\"FEIR014_3\"] = \"277.mat\"\n",
        "# FE Inner Race 0.021 inches\n",
        "aquisitions[\"FEIR021_0\"] = \"270.mat\"\n",
        "aquisitions[\"FEIR021_1\"] = \"271.mat\"\n",
        "aquisitions[\"FEIR021_2\"] = \"272.mat\"\n",
        "aquisitions[\"FEIR021_3\"] = \"273.mat\"\n",
        "# FE Ball 0.007 inches\n",
        "aquisitions[\"FEB007_0\"] = \"282.mat\"\n",
        "aquisitions[\"FEB007_1\"] = \"283.mat\"\n",
        "aquisitions[\"FEB007_2\"] = \"284.mat\"\n",
        "aquisitions[\"FEB007_3\"] = \"285.mat\"\n",
        "# FE Ball 0.014 inches\n",
        "aquisitions[\"FEB014_0\"] = \"286.mat\"\n",
        "aquisitions[\"FEB014_1\"] = \"287.mat\"\n",
        "aquisitions[\"FEB014_2\"] = \"288.mat\"\n",
        "aquisitions[\"FEB014_3\"] = \"289.mat\"\n",
        "# FE Ball 0.021 inches\n",
        "aquisitions[\"FEB021_0\"] = \"290.mat\"\n",
        "aquisitions[\"FEB021_1\"] = \"291.mat\"\n",
        "aquisitions[\"FEB021_2\"] = \"292.mat\"\n",
        "aquisitions[\"FEB021_3\"] = \"293.mat\"\n",
        "# FE Outer race 0.007 inches centered @6:00\n",
        "aquisitions[\"FEOR007@6_0\"] = \"294.mat\"\n",
        "aquisitions[\"FEOR007@6_1\"] = \"295.mat\"\n",
        "aquisitions[\"FEOR007@6_2\"] = \"296.mat\"\n",
        "aquisitions[\"FEOR007@6_3\"] = \"297.mat\"\n",
        "# FE Outer race 0.007 inches centered @3:00\n",
        "aquisitions[\"FEOR007@3_0\"] = \"298.mat\"\n",
        "aquisitions[\"FEOR007@3_1\"] = \"299.mat\"\n",
        "aquisitions[\"FEOR007@3_2\"] = \"300.mat\"\n",
        "aquisitions[\"FEOR007@3_3\"] = \"301.mat\"\n",
        "# FE Outer race 0.014 inches centered @3:00\n",
        "aquisitions[\"FEOR014@3_0\"] = \"310.mat\"\n",
        "aquisitions[\"FEOR014@3_1\"] = \"309.mat\"\n",
        "aquisitions[\"FEOR014@3_2\"] = \"311.mat\"\n",
        "aquisitions[\"FEOR014@3_3\"] = \"312.mat\"\n",
        "# FE Outer race 0.007 inches centered @12:00\n",
        "aquisitions[\"FEOR007@12_0\"] = \"302.mat\"\n",
        "aquisitions[\"FEOR007@12_1\"] = \"305.mat\"\n",
        "aquisitions[\"FEOR007@12_2\"] = \"306.mat\"\n",
        "aquisitions[\"FEOR007@12_3\"] = \"307.mat\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R_4WiLNSyrMB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generate a dictionary linking the labels with values to keep consistence"
      ]
    },
    {
      "metadata": {
        "id": "zHDI4LWbyoP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_labels_dict(aquisitions):\n",
        "  labels_dict = {}\n",
        "  value = 0\n",
        "  for key in aquisitions.keys():\n",
        "    label = key.split('_')[0]\n",
        "    if not label in labels_dict:\n",
        "      labels_dict[label] = value\n",
        "      value += 1\n",
        "  return labels_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Rz0cKigF7q6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert Matlab file into tensors"
      ]
    },
    {
      "metadata": {
        "id": "2tn5IFqkCHQx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "\n",
        "def aquisition2tensor(file_name, sample_size=512):\n",
        "  print(file_name, end=' ')\n",
        "  matlab_file = scipy.io.loadmat(file_name)\n",
        "  DE_time = [key for key in matlab_file if key.endswith(\"DE_time\")][0] #Find the DRIVE END aquisition key name\n",
        "  FE_time = [key for key in matlab_file if key.endswith(\"FE_time\")][0] #Find the FAN END aquisition key name\n",
        "  signal_begin = 0\n",
        "  aquisition_size = max(len(matlab_file[DE_time]),len(matlab_file[FE_time]))\n",
        "  DE_samples = []\n",
        "  FE_samples = []\n",
        "  while signal_begin + sample_size < aquisition_size:\n",
        "    DE_samples.append([item for sublist in matlab_file[DE_time][signal_begin:signal_begin+sample_size] for item in sublist])\n",
        "    FE_samples.append([item for sublist in matlab_file[FE_time][signal_begin:signal_begin+sample_size] for item in sublist])\n",
        "    signal_begin += sample_size\n",
        "  sample_tensor = np.stack([DE_samples,FE_samples],axis=2).astype('float32')\n",
        "  return sample_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x-G4gjyuvA7a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Extract datasets from aquisitions"
      ]
    },
    {
      "metadata": {
        "id": "YC4rhGwWMKT7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def concatenate_datasets(xd,yd,xo,yo):\n",
        "  if xd is None or yd is None:\n",
        "    xd = xo\n",
        "    yd = yo\n",
        "  else:\n",
        "    xd = np.concatenate((xd,xo))\n",
        "    yd = np.concatenate((yd,yo))\n",
        "  return xd,yd\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "def aquisitions_from_load(load, aquisitions, labels_dict,\n",
        "                          url=\"http://csegroups.case.edu/sites/default/files/bearingdatacenter/files/Datafiles/\"\n",
        "                         ):\n",
        "  samples = None\n",
        "  labels = None\n",
        "  for key in aquisitions:\n",
        "    if key.endswith(\"_\"+str(load)):\n",
        "      file_name = aquisitions[key]\n",
        "      urllib.request.urlretrieve(url+file_name, file_name)\n",
        "      aquisition_samples = aquisition2tensor(file_name)\n",
        "      aquisition_labels = np.ones(aquisition_samples.shape[0])*labels_dict[key.split('_')[0]]\n",
        "      samples,labels = concatenate_datasets(samples,labels,aquisition_samples,aquisition_labels)\n",
        "  print(load)\n",
        "  return samples,labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sfwmQa0RJMvb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Exrtract samples"
      ]
    },
    {
      "metadata": {
        "id": "HSASqQsHcgtj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "e1a5220a-85ba-4319-8744-0fcc76f1e943"
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "labels_dict = get_labels_dict(aquisitions)\n",
        "print(labels_dict.keys())\n",
        "\n",
        "x0,y0 = aquisitions_from_load(0,aquisitions,labels_dict)\n",
        "x1,y1 = aquisitions_from_load(1,aquisitions,labels_dict)\n",
        "x2,y2 = aquisitions_from_load(2,aquisitions,labels_dict)\n",
        "x3,y3 = aquisitions_from_load(3,aquisitions,labels_dict)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['Normal', 'DEIR007', 'DEIR014', 'DEIR021', 'DEB007', 'DEB014', 'DEB021', 'DEOR007@6', 'DEOR014@6', 'DEOR021@6', 'DEOR007@3', 'DEOR021@3', 'DEOR007@12', 'DEOR021@12', 'FEIR007', 'FEIR014', 'FEIR021', 'FEB007', 'FEB014', 'FEB021', 'FEOR007@6', 'FEOR007@3', 'FEOR014@3', 'FEOR007@12'])\n",
            "97.mat 105.mat 169.mat 209.mat 118.mat 185.mat 222.mat 130.mat 197.mat 234.mat 144.mat 246.mat 156.mat 258.mat 278.mat 274.mat 270.mat 282.mat 286.mat 290.mat 294.mat 298.mat 310.mat 302.mat 0\n",
            "98.mat 106.mat 170.mat 210.mat 119.mat 186.mat 223.mat 131.mat 198.mat 235.mat 145.mat 247.mat 158.mat 259.mat 279.mat 275.mat 271.mat 283.mat 287.mat 291.mat 295.mat 299.mat 309.mat 305.mat 1\n",
            "99.mat 107.mat 171.mat 211.mat 120.mat 187.mat 224.mat 132.mat 199.mat 236.mat 146.mat 248.mat 159.mat 260.mat 280.mat 276.mat 272.mat 284.mat 288.mat 292.mat 296.mat 300.mat 311.mat 306.mat 2\n",
            "100.mat 108.mat 172.mat 212.mat 121.mat 188.mat 225.mat 133.mat 200.mat 237.mat 147.mat 249.mat 160.mat 261.mat 281.mat 277.mat 273.mat 285.mat 289.mat 293.mat 297.mat 301.mat 312.mat 307.mat 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_QgaHQFpBuDw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define f1-score macro averaged"
      ]
    },
    {
      "metadata": {
        "id": "HdRZ_4pJBzfk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "def f1_score_macro(y_true,y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hPLjBiao2GIK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define architecture model"
      ]
    },
    {
      "metadata": {
        "id": "fpcZrU4Mu9Vk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "b0cba9be-9dee-42f4-b191-aaa19a3d90fa"
      },
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import Input\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "\n",
        "signal_input = Input(shape=(x0.shape[1],x0.shape[-1]), dtype='float32', name='signal')\n",
        "x = layers.Conv1D(64, 128, activation='relu')(signal_input)\n",
        "x = layers.Flatten()(x)\n",
        "condition_output = layers.Dense(len(labels_dict),activation='softmax',name='condition')(x)\n",
        "\n",
        "model = Model(signal_input, condition_output)\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "signal (InputLayer)          (None, 512, 2)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 385, 64)           16448     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 24640)             0         \n",
            "_________________________________________________________________\n",
            "condition (Dense)            (None, 24)                591384    \n",
            "=================================================================\n",
            "Total params: 607,832\n",
            "Trainable params: 607,832\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y0xe9oYrW1lv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Perform experiments"
      ]
    },
    {
      "metadata": {
        "id": "UU0B-KF-W0eV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17938
        },
        "outputId": "de8e4cc6-173c-444d-bed1-3bb30bb31dd2"
      },
      "cell_type": "code",
      "source": [
        "loads = list(range(4))\n",
        "nrounds = 10\n",
        "results = []\n",
        "summary = []\n",
        "for i,fold in enumerate(loads):\n",
        "  print(fold)\n",
        "  x_test, y_test = eval('x'+str(fold)),eval('y'+str(fold))\n",
        "  y_test = to_categorical(y_test)\n",
        "  x_train,y_train = None,None\n",
        "  for tfold in loads[:i]+loads[i+1:]:\n",
        "    x_train,y_train = concatenate_datasets(x_train,y_train,eval('x'+str(tfold)),eval('y'+str(tfold)))\n",
        "  y_train = to_categorical(y_train)\n",
        "  print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)\n",
        "  for round in range(nrounds):\n",
        "    print(round+1)\n",
        "    model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['accuracy',f1_score_macro])\n",
        "    history = model.fit(x_train,y_train,epochs=10,validation_split=0.33)\n",
        "    results.append(model.evaluate(x_test, y_test))\n",
        "    print(results[-1])\n",
        "  print(np.asarray(results[-nrounds:]))\n",
        "  print(np.mean(results[-nrounds:],axis=0),np.std(results[-nrounds:],axis=0))\n",
        "  summary.append(np.mean(results[-nrounds:],axis=0))\n",
        "\n",
        "print(np.asarray(results))\n",
        "print(np.mean(results,axis=0),np.std(results,axis=0))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "(19208, 512, 2) (19208, 24) (5931, 512, 2) (5931, 24)\n",
            "1\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 6s 493us/step - loss: 0.0092 - acc: 0.8365 - f1_score_macro: 0.8131 - val_loss: 0.0073 - val_acc: 0.8669 - val_f1_score_macro: 0.8618\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 3.3326e-04 - acc: 0.9951 - f1_score_macro: 0.9953 - val_loss: 0.0012 - val_acc: 0.9820 - val_f1_score_macro: 0.9813\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 1.0034e-04 - acc: 0.9984 - f1_score_macro: 0.9984 - val_loss: 0.0021 - val_acc: 0.9659 - val_f1_score_macro: 0.9657\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 325us/step - loss: 4.8079e-05 - acc: 0.9995 - f1_score_macro: 0.9995 - val_loss: 0.0017 - val_acc: 0.9729 - val_f1_score_macro: 0.9727\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 3.7297e-05 - acc: 0.9995 - f1_score_macro: 0.9995 - val_loss: 0.0012 - val_acc: 0.9798 - val_f1_score_macro: 0.9796\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 323us/step - loss: 3.3603e-05 - acc: 0.9995 - f1_score_macro: 0.9996 - val_loss: 0.0019 - val_acc: 0.9697 - val_f1_score_macro: 0.9697\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 325us/step - loss: 2.6106e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0013 - val_acc: 0.9795 - val_f1_score_macro: 0.9800\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 326us/step - loss: 2.9931e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 8.8993e-04 - val_acc: 0.9866 - val_f1_score_macro: 0.9864\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 325us/step - loss: 3.1571e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 9.3113e-04 - val_acc: 0.9863 - val_f1_score_macro: 0.9864\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 324us/step - loss: 3.1034e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0011 - val_acc: 0.9815 - val_f1_score_macro: 0.9820\n",
            "5931/5931 [==============================] - 1s 154us/step\n",
            "[0.005839109635895712, 0.9118192548033078, 0.9121635336635527]\n",
            "2\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 4s 340us/step - loss: 2.8901e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 8.6747e-04 - val_acc: 0.9860 - val_f1_score_macro: 0.9858\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 324us/step - loss: 2.9595e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0025 - val_acc: 0.9609 - val_f1_score_macro: 0.9606\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 3.1773e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0010 - val_acc: 0.9839 - val_f1_score_macro: 0.9837\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 2.8951e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 6.8288e-04 - val_acc: 0.9899 - val_f1_score_macro: 0.9898\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 2.8891e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 6.1989e-04 - val_acc: 0.9902 - val_f1_score_macro: 0.9901\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 3.1634e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0011 - val_acc: 0.9831 - val_f1_score_macro: 0.9833\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 3.0776e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 9.8347e-04 - val_acc: 0.9836 - val_f1_score_macro: 0.9836\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 3.1240e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0015 - val_acc: 0.9751 - val_f1_score_macro: 0.9748\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 3.1390e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 8.1064e-04 - val_acc: 0.9877 - val_f1_score_macro: 0.9878\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 3.0707e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0011 - val_acc: 0.9812 - val_f1_score_macro: 0.9811\n",
            "5931/5931 [==============================] - 1s 156us/step\n",
            "[0.00751323504942868, 0.8909121565062247, 0.8910675517143155]\n",
            "3\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 4s 342us/step - loss: 3.1536e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 9.9622e-04 - val_acc: 0.9841 - val_f1_score_macro: 0.9839\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 2.7964e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 7.4469e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9887\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 3.1696e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 6.6753e-04 - val_acc: 0.9896 - val_f1_score_macro: 0.9895\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 3.0268e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0014 - val_acc: 0.9782 - val_f1_score_macro: 0.9781\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 3.1913e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 9.0366e-04 - val_acc: 0.9863 - val_f1_score_macro: 0.9856\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 2.6593e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0011 - val_acc: 0.9834 - val_f1_score_macro: 0.9832\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 1.8429e-05 - acc: 0.9998 - f1_score_macro: 0.9997 - val_loss: 0.0013 - val_acc: 0.9800 - val_f1_score_macro: 0.9800\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 1.0492e-05 - acc: 0.9998 - f1_score_macro: 0.9998 - val_loss: 8.6885e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9871\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 3.1330e-07 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.3011e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9855\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 3.9280e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9881e-04 - val_acc: 0.9864 - val_f1_score_macro: 0.9863\n",
            "5931/5931 [==============================] - 1s 155us/step\n",
            "[0.006459109054255728, 0.9072669027045009, 0.9068513493215509]\n",
            "4\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 4s 348us/step - loss: 1.0516e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.8162e-04 - val_acc: 0.9860 - val_f1_score_macro: 0.9861\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 335us/step - loss: 8.2533e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.4823e-04 - val_acc: 0.9844 - val_f1_score_macro: 0.9844\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 7.2131e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.1120e-04 - val_acc: 0.9855 - val_f1_score_macro: 0.9854\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 6.4205e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.2818e-04 - val_acc: 0.9847 - val_f1_score_macro: 0.9848\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 5.8606e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.6029e-04 - val_acc: 0.9866 - val_f1_score_macro: 0.9862\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 5.4834e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.8676e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9855\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 5.0614e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.1525e-04 - val_acc: 0.9852 - val_f1_score_macro: 0.9852\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 337us/step - loss: 4.7702e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.6225e-04 - val_acc: 0.9866 - val_f1_score_macro: 0.9864\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 5s 354us/step - loss: 4.5706e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.7699e-04 - val_acc: 0.9863 - val_f1_score_macro: 0.9860\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 5s 360us/step - loss: 4.3136e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.8506e-04 - val_acc: 0.9860 - val_f1_score_macro: 0.9860\n",
            "5931/5931 [==============================] - 1s 174us/step\n",
            "[0.006452316390349436, 0.9074355083359291, 0.906737461618299]\n",
            "5\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 5s 364us/step - loss: 4.0981e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.2852e-04 - val_acc: 0.9849 - val_f1_score_macro: 0.9849\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 3.9646e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.6271e-04 - val_acc: 0.9867 - val_f1_score_macro: 0.9866\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 3.8096e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.8428e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9859\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 3.6647e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0836e-04 - val_acc: 0.9852 - val_f1_score_macro: 0.9853\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 3.4995e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.5858e-04 - val_acc: 0.9866 - val_f1_score_macro: 0.9864\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 3.3987e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9936e-04 - val_acc: 0.9853 - val_f1_score_macro: 0.9854\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 327us/step - loss: 3.3083e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9535e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9855\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 3.2099e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.5349e-04 - val_acc: 0.9871 - val_f1_score_macro: 0.9866\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 326us/step - loss: 3.1220e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.3703e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9869\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 3.0299e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.4997e-04 - val_acc: 0.9867 - val_f1_score_macro: 0.9865\n",
            "5931/5931 [==============================] - 1s 155us/step\n",
            "[0.006417418704123246, 0.9079413252302133, 0.9073207792233223]\n",
            "6\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 4s 345us/step - loss: 2.9491e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.3577e-04 - val_acc: 0.9874 - val_f1_score_macro: 0.9869\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 326us/step - loss: 2.8558e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.7585e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9859\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 326us/step - loss: 2.8058e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.7425e-04 - val_acc: 0.9863 - val_f1_score_macro: 0.9860\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 2.7329e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.3693e-04 - val_acc: 0.9871 - val_f1_score_macro: 0.9867\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 2.6669e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.4994e-04 - val_acc: 0.9867 - val_f1_score_macro: 0.9863\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 2.6073e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.6202e-04 - val_acc: 0.9866 - val_f1_score_macro: 0.9863\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 334us/step - loss: 2.5509e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.5012e-04 - val_acc: 0.9867 - val_f1_score_macro: 0.9863\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 2.4930e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.4145e-04 - val_acc: 0.9871 - val_f1_score_macro: 0.9867\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 2.4412e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.5692e-04 - val_acc: 0.9864 - val_f1_score_macro: 0.9863\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 2.3918e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.6023e-04 - val_acc: 0.9866 - val_f1_score_macro: 0.9863\n",
            "5931/5931 [==============================] - 1s 158us/step\n",
            "[0.006409889980564344, 0.9076041140176055, 0.9074574717380329]\n",
            "7\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 5s 361us/step - loss: 2.3447e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.4936e-04 - val_acc: 0.9871 - val_f1_score_macro: 0.9867\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 2.3040e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.5104e-04 - val_acc: 0.9867 - val_f1_score_macro: 0.9863\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 2.2605e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.3546e-04 - val_acc: 0.9871 - val_f1_score_macro: 0.9867\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 2.2145e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.5172e-04 - val_acc: 0.9867 - val_f1_score_macro: 0.9863\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 327us/step - loss: 2.1800e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.3525e-04 - val_acc: 0.9871 - val_f1_score_macro: 0.9867\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 2.1335e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.3068e-04 - val_acc: 0.9871 - val_f1_score_macro: 0.9868\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 2.1017e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.2741e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9869\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 2.0678e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.3971e-04 - val_acc: 0.9871 - val_f1_score_macro: 0.9867\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 2.0400e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.4005e-04 - val_acc: 0.9869 - val_f1_score_macro: 0.9865\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 2.0068e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.3175e-04 - val_acc: 0.9869 - val_f1_score_macro: 0.9866\n",
            "5931/5931 [==============================] - 1s 162us/step\n",
            "[0.0064315168946374925, 0.9079413252302133, 0.907485590578432]\n",
            "8\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 5s 355us/step - loss: 1.9697e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.2205e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9868\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 334us/step - loss: 1.9360e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.4068e-04 - val_acc: 0.9869 - val_f1_score_macro: 0.9865\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 1.9106e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.4332e-04 - val_acc: 0.9867 - val_f1_score_macro: 0.9864\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 1.8918e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.3412e-04 - val_acc: 0.9867 - val_f1_score_macro: 0.9863\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 1.8593e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.3287e-04 - val_acc: 0.9869 - val_f1_score_macro: 0.9865\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 1.8330e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.2620e-04 - val_acc: 0.9871 - val_f1_score_macro: 0.9866\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 1.8062e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1101e-04 - val_acc: 0.9874 - val_f1_score_macro: 0.9871\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 1.7833e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.2196e-04 - val_acc: 0.9871 - val_f1_score_macro: 0.9867\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 1.7594e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.2062e-04 - val_acc: 0.9871 - val_f1_score_macro: 0.9867\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 1.7325e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.0530e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9870\n",
            "5931/5931 [==============================] - 1s 156us/step\n",
            "[0.006410880162306147, 0.9086157477559257, 0.9082369860761023]\n",
            "9\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 5s 352us/step - loss: 1.7128e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1570e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9869\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 1.6847e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.0298e-04 - val_acc: 0.9874 - val_f1_score_macro: 0.9871\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 1.6678e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.3187e-04 - val_acc: 0.9867 - val_f1_score_macro: 0.9863\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 1.6475e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.2336e-04 - val_acc: 0.9871 - val_f1_score_macro: 0.9867\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 1.6270e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1496e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9869\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 1.6078e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1613e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9870\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 334us/step - loss: 1.5891e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1888e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9869\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 1.5590e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.0038e-04 - val_acc: 0.9874 - val_f1_score_macro: 0.9872\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 1.5536e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1173e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9869\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 326us/step - loss: 1.5369e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1633e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9869\n",
            "5931/5931 [==============================] - 1s 155us/step\n",
            "[0.006396905013232696, 0.9084471421244976, 0.9083623940075174]\n",
            "10\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 5s 353us/step - loss: 1.5175e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1740e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9868\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 1.5015e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.0836e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9869\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 1.4823e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.0882e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9869\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 1.4670e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1555e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9869\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 1.4541e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.2277e-04 - val_acc: 0.9871 - val_f1_score_macro: 0.9867\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 336us/step - loss: 1.4378e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.0843e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9869\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 1.4203e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1473e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9868\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 1.4090e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1142e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9868\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 1.3938e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.1368e-04 - val_acc: 0.9872 - val_f1_score_macro: 0.9868\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 1.3791e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.0555e-04 - val_acc: 0.9874 - val_f1_score_macro: 0.9870\n",
            "5931/5931 [==============================] - 1s 160us/step\n",
            "[0.0063709642121256935, 0.9087843533873537, 0.9086147811577224]\n",
            "[[0.00583911 0.91181925 0.91216353]\n",
            " [0.00751324 0.89091216 0.89106755]\n",
            " [0.00645911 0.9072669  0.90685135]\n",
            " [0.00645232 0.90743551 0.90673746]\n",
            " [0.00641742 0.90794133 0.90732078]\n",
            " [0.00640989 0.90760411 0.90745747]\n",
            " [0.00643152 0.90794133 0.90748559]\n",
            " [0.00641088 0.90861575 0.90823699]\n",
            " [0.00639691 0.90844714 0.90836239]\n",
            " [0.00637096 0.90878435 0.90861478]]\n",
            "[0.00647013 0.90667678 0.90642979] [0.00038901 0.00539709 0.0053281 ]\n",
            "1\n",
            "(18739, 512, 2) (18739, 24) (6400, 512, 2) (6400, 24)\n",
            "1\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 359us/step - loss: 4.9861e-04 - acc: 0.9919 - f1_score_macro: 0.9921 - val_loss: 0.0024 - val_acc: 0.9620 - val_f1_score_macro: 0.9620\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 7.1338e-05 - acc: 0.9987 - f1_score_macro: 0.9988 - val_loss: 0.0014 - val_acc: 0.9780 - val_f1_score_macro: 0.9782\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 1.2625e-05 - acc: 0.9998 - f1_score_macro: 0.9998 - val_loss: 0.0011 - val_acc: 0.9822 - val_f1_score_macro: 0.9826\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 1.2534e-05 - acc: 0.9998 - f1_score_macro: 0.9998 - val_loss: 0.0021 - val_acc: 0.9690 - val_f1_score_macro: 0.9696\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 9.3761e-06 - acc: 0.9999 - f1_score_macro: 0.9999 - val_loss: 9.1248e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9860\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 6.3140e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.5318e-04 - val_acc: 0.9884 - val_f1_score_macro: 0.9878\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 2.3028e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.5486e-04 - val_acc: 0.9874 - val_f1_score_macro: 0.9874\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 339us/step - loss: 1.6762e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.7583e-04 - val_acc: 0.9880 - val_f1_score_macro: 0.9866\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 355us/step - loss: 1.3531e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.6895e-04 - val_acc: 0.9880 - val_f1_score_macro: 0.9875\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 358us/step - loss: 1.1448e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.2072e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9885\n",
            "6400/6400 [==============================] - 1s 171us/step\n",
            "[6.649761055082513e-05, 0.9990625, 0.9990624988079071]\n",
            "2\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 386us/step - loss: 1.0219e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.3268e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9879\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 9.0587e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.5007e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9877\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 8.1219e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.2661e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9884\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 7.6452e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.4116e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9882\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 7.0369e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.5482e-04 - val_acc: 0.9882 - val_f1_score_macro: 0.9875\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 6.4661e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.6655e-04 - val_acc: 0.9882 - val_f1_score_macro: 0.9873\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 6.1260e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.3881e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9881\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 5.7789e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1767e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9887\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 5.5102e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0185e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9892\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 5.2159e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.5839e-04 - val_acc: 0.9884 - val_f1_score_macro: 0.9875\n",
            "6400/6400 [==============================] - 1s 159us/step\n",
            "[7.243692621534771e-05, 0.9990625, 0.9989831334352494]\n",
            "3\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 360us/step - loss: 5.0381e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.3841e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9883\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 4.8209e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.3208e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9886\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 4.6211e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.5133e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9883\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 4.3233e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.4849e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9880\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 336us/step - loss: 4.2221e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.3251e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9886\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 4.0872e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9302e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9894\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 3.9015e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.4017e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9884\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 3.8047e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9148e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9892\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 3.7078e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.2821e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9889\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 3.6010e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1294e-04 - val_acc: 0.9892 - val_f1_score_macro: 0.9889\n",
            "6400/6400 [==============================] - 1s 157us/step\n",
            "[6.863012565025868e-05, 0.9990625, 0.9989831334352494]\n",
            "4\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 361us/step - loss: 3.4651e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.3169e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9886\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 3.3669e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1941e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9886\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 3.2957e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.2269e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9887\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 3.1945e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.2038e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9887\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 3.1030e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.2864e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9883\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 3.0669e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1791e-04 - val_acc: 0.9888 - val_f1_score_macro: 0.9889\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 2.9698e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9475e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9893\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 2.9119e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1097e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9889\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 2.8340e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.4273e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9883\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 2.7907e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.2764e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9885\n",
            "6400/6400 [==============================] - 1s 155us/step\n",
            "[7.04518903116277e-05, 0.9990625, 0.9989831334352494]\n",
            "5\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 360us/step - loss: 2.7039e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1428e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9887\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 2.6607e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9513e-04 - val_acc: 0.9892 - val_f1_score_macro: 0.9888\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 2.6155e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.2553e-04 - val_acc: 0.9885 - val_f1_score_macro: 0.9884\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 2.5469e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.7828e-04 - val_acc: 0.9898 - val_f1_score_macro: 0.9897\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 2.5108e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9213e-04 - val_acc: 0.9897 - val_f1_score_macro: 0.9894\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 2.4738e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0523e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9888\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 2.4189e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0773e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9890\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 2.3728e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0572e-04 - val_acc: 0.9892 - val_f1_score_macro: 0.9888\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 2.3466e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0272e-04 - val_acc: 0.9892 - val_f1_score_macro: 0.9888\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 2.2709e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0666e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9889\n",
            "6400/6400 [==============================] - 1s 157us/step\n",
            "[7.090503713454789e-05, 0.9990625, 0.9989831334352494]\n",
            "6\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 365us/step - loss: 2.2565e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0957e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9890\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 2.2139e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.1664e-04 - val_acc: 0.9887 - val_f1_score_macro: 0.9886\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 2.1956e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0341e-04 - val_acc: 0.9893 - val_f1_score_macro: 0.9892\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 2.1205e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9139e-04 - val_acc: 0.9893 - val_f1_score_macro: 0.9893\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 2.1134e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9635e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9892\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 2.0727e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8773e-04 - val_acc: 0.9897 - val_f1_score_macro: 0.9893\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 2.0452e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8781e-04 - val_acc: 0.9897 - val_f1_score_macro: 0.9894\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 2.0358e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9291e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9892\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 325us/step - loss: 1.9835e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8735e-04 - val_acc: 0.9897 - val_f1_score_macro: 0.9895\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 1.9646e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9880e-04 - val_acc: 0.9893 - val_f1_score_macro: 0.9891\n",
            "6400/6400 [==============================] - 1s 158us/step\n",
            "[6.849363075108757e-05, 0.9990625, 0.9989831334352494]\n",
            "7\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 365us/step - loss: 1.9331e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8639e-04 - val_acc: 0.9897 - val_f1_score_macro: 0.9893\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 1.9143e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0249e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9892\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 325us/step - loss: 1.8842e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8772e-04 - val_acc: 0.9897 - val_f1_score_macro: 0.9894\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 1.8500e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0593e-04 - val_acc: 0.9892 - val_f1_score_macro: 0.9891\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 1.8380e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0886e-04 - val_acc: 0.9892 - val_f1_score_macro: 0.9891\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 1.7981e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.2004e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9887\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 1.7958e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9387e-04 - val_acc: 0.9897 - val_f1_score_macro: 0.9893\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 1.7622e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9847e-04 - val_acc: 0.9893 - val_f1_score_macro: 0.9891\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 1.7429e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8971e-04 - val_acc: 0.9897 - val_f1_score_macro: 0.9894\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 1.7235e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9288e-04 - val_acc: 0.9897 - val_f1_score_macro: 0.9893\n",
            "6400/6400 [==============================] - 1s 156us/step\n",
            "[6.753268888672428e-05, 0.9990625, 0.9989831334352494]\n",
            "8\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 364us/step - loss: 1.7015e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0010e-04 - val_acc: 0.9893 - val_f1_score_macro: 0.9890\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 1.6833e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9744e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9892\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 1.6604e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0599e-04 - val_acc: 0.9893 - val_f1_score_macro: 0.9888\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 1.6463e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8824e-04 - val_acc: 0.9898 - val_f1_score_macro: 0.9895\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 1.6226e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9446e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9892\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 1.6013e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0781e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9887\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 325us/step - loss: 1.5868e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0336e-04 - val_acc: 0.9890 - val_f1_score_macro: 0.9888\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 1.5628e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0323e-04 - val_acc: 0.9892 - val_f1_score_macro: 0.9891\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 1.5448e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8931e-04 - val_acc: 0.9897 - val_f1_score_macro: 0.9893\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 340us/step - loss: 1.5344e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9403e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9892\n",
            "6400/6400 [==============================] - 1s 166us/step\n",
            "[6.942348717199132e-05, 0.9990625, 0.9989831334352494]\n",
            "9\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 404us/step - loss: 1.5221e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8955e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9893\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 5s 362us/step - loss: 1.4997e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0382e-04 - val_acc: 0.9893 - val_f1_score_macro: 0.9892\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 351us/step - loss: 1.4880e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9494e-04 - val_acc: 0.9893 - val_f1_score_macro: 0.9893\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 1.4739e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9793e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9893\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 1.4576e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0635e-04 - val_acc: 0.9892 - val_f1_score_macro: 0.9888\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 1.4447e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8896e-04 - val_acc: 0.9897 - val_f1_score_macro: 0.9895\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 325us/step - loss: 1.4276e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0018e-04 - val_acc: 0.9893 - val_f1_score_macro: 0.9892\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 1.4182e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9450e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9894\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 1.4032e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0029e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9893\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 1.3870e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0669e-04 - val_acc: 0.9892 - val_f1_score_macro: 0.9889\n",
            "6400/6400 [==============================] - 1s 156us/step\n",
            "[6.817994114328582e-05, 0.9990625, 0.9989831334352494]\n",
            "10\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 371us/step - loss: 1.3754e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9679e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9893\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 1.3644e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9908e-04 - val_acc: 0.9893 - val_f1_score_macro: 0.9892\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 1.3516e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8757e-04 - val_acc: 0.9897 - val_f1_score_macro: 0.9896\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 1.3385e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8775e-04 - val_acc: 0.9897 - val_f1_score_macro: 0.9896\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 1.3228e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9794e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9895\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 1.3161e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9688e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9895\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 1.3003e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8237e-04 - val_acc: 0.9897 - val_f1_score_macro: 0.9897\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 327us/step - loss: 1.2872e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.9615e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9895\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 326us/step - loss: 1.2794e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 6.8828e-04 - val_acc: 0.9897 - val_f1_score_macro: 0.9896\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 1.2708e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 7.0062e-04 - val_acc: 0.9895 - val_f1_score_macro: 0.9892\n",
            "6400/6400 [==============================] - 1s 156us/step\n",
            "[6.8293513934074e-05, 0.9990625, 0.9989831334352494]\n",
            "[[6.64976106e-05 9.99062500e-01 9.99062499e-01]\n",
            " [7.24369262e-05 9.99062500e-01 9.98983133e-01]\n",
            " [6.86301257e-05 9.99062500e-01 9.98983133e-01]\n",
            " [7.04518903e-05 9.99062500e-01 9.98983133e-01]\n",
            " [7.09050371e-05 9.99062500e-01 9.98983133e-01]\n",
            " [6.84936308e-05 9.99062500e-01 9.98983133e-01]\n",
            " [6.75326889e-05 9.99062500e-01 9.98983133e-01]\n",
            " [6.94234872e-05 9.99062500e-01 9.98983133e-01]\n",
            " [6.81799411e-05 9.99062500e-01 9.98983133e-01]\n",
            " [6.82935139e-05 9.99062500e-01 9.98983133e-01]]\n",
            "[6.90844852e-05 9.99062500e-01 9.98991070e-01] [1.66244905e-06 2.22044605e-16 2.38096118e-05]\n",
            "2\n",
            "(18736, 512, 2) (18736, 24) (6403, 512, 2) (6403, 24)\n",
            "1\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 371us/step - loss: 4.0717e-05 - acc: 0.9993 - f1_score_macro: 0.9993 - val_loss: 0.0010 - val_acc: 0.9856 - val_f1_score_macro: 0.9853\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 1.6032e-06 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0011 - val_acc: 0.9843 - val_f1_score_macro: 0.9840\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 1.7362e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0010 - val_acc: 0.9854 - val_f1_score_macro: 0.9856\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 1.0831e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0010 - val_acc: 0.9853 - val_f1_score_macro: 0.9855\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 8.0094e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.6575e-04 - val_acc: 0.9858 - val_f1_score_macro: 0.9858\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 326us/step - loss: 6.8787e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.3112e-04 - val_acc: 0.9863 - val_f1_score_macro: 0.9862\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 7.0696e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.8235e-04 - val_acc: 0.9858 - val_f1_score_macro: 0.9858\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 5.5044e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.3478e-04 - val_acc: 0.9858 - val_f1_score_macro: 0.9860\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 326us/step - loss: 4.7791e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0010 - val_acc: 0.9853 - val_f1_score_macro: 0.9853\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 4.5003e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.8229e-04 - val_acc: 0.9851 - val_f1_score_macro: 0.9853\n",
            "6403/6403 [==============================] - 1s 154us/step\n",
            "[6.396238375216802e-10, 1.0, 1.0]\n",
            "2\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 374us/step - loss: 4.4739e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.6534e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9855\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 3.9790e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.7040e-04 - val_acc: 0.9853 - val_f1_score_macro: 0.9855\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 3.8395e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.5261e-04 - val_acc: 0.9854 - val_f1_score_macro: 0.9854\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 3.7027e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.6245e-04 - val_acc: 0.9854 - val_f1_score_macro: 0.9856\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 3.4978e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.4516e-04 - val_acc: 0.9854 - val_f1_score_macro: 0.9854\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 3.4334e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.2280e-04 - val_acc: 0.9854 - val_f1_score_macro: 0.9857\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 3.2188e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.3198e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9857\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 3.2010e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.3663e-04 - val_acc: 0.9854 - val_f1_score_macro: 0.9856\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 2.9521e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.4657e-04 - val_acc: 0.9853 - val_f1_score_macro: 0.9853\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 2.9026e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.3419e-04 - val_acc: 0.9854 - val_f1_score_macro: 0.9854\n",
            "6403/6403 [==============================] - 1s 157us/step\n",
            "[5.161998245609077e-10, 1.0, 1.0]\n",
            "3\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 369us/step - loss: 2.8492e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.2089e-04 - val_acc: 0.9858 - val_f1_score_macro: 0.9858\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 2.6735e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.3151e-04 - val_acc: 0.9858 - val_f1_score_macro: 0.9858\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 2.6713e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9736e-04 - val_acc: 0.9859 - val_f1_score_macro: 0.9860\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 2.6086e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.3701e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9856\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 2.4916e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0660e-04 - val_acc: 0.9859 - val_f1_score_macro: 0.9861\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 2.4395e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0468e-04 - val_acc: 0.9858 - val_f1_score_macro: 0.9858\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 323us/step - loss: 2.3974e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.2349e-04 - val_acc: 0.9854 - val_f1_score_macro: 0.9856\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 2.3568e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.3345e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9856\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 2.3181e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.1970e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9856\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 324us/step - loss: 2.2297e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.1012e-04 - val_acc: 0.9859 - val_f1_score_macro: 0.9860\n",
            "6403/6403 [==============================] - 1s 155us/step\n",
            "[4.1603840685311326e-10, 1.0, 1.0]\n",
            "4\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 372us/step - loss: 2.1761e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.3615e-04 - val_acc: 0.9854 - val_f1_score_macro: 0.9856\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 2.1520e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.2153e-04 - val_acc: 0.9854 - val_f1_score_macro: 0.9856\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 2.0887e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.1996e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9857\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 2.0748e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.1931e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9856\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 2.0145e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.2530e-04 - val_acc: 0.9854 - val_f1_score_macro: 0.9856\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 1.9583e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.2231e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9857\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 1.9377e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.2467e-04 - val_acc: 0.9854 - val_f1_score_macro: 0.9856\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 1.9132e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.2844e-04 - val_acc: 0.9854 - val_f1_score_macro: 0.9856\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 326us/step - loss: 1.8682e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0016e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9860\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 326us/step - loss: 1.8482e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.2675e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9856\n",
            "6403/6403 [==============================] - 1s 156us/step\n",
            "[3.5272458405121913e-10, 1.0, 1.0]\n",
            "5\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 375us/step - loss: 1.8190e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.1309e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9856\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 1.7801e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.2059e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9857\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 1.7575e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.8629e-04 - val_acc: 0.9864 - val_f1_score_macro: 0.9864\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 326us/step - loss: 1.7187e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.2032e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9856\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 1.6986e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0518e-04 - val_acc: 0.9858 - val_f1_score_macro: 0.9859\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 330us/step - loss: 1.7000e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0619e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9857\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 1.6490e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.1697e-04 - val_acc: 0.9854 - val_f1_score_macro: 0.9856\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 1.6191e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.1963e-04 - val_acc: 0.9854 - val_f1_score_macro: 0.9856\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 1.5991e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.1158e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9859\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 1.5751e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0215e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9862\n",
            "6403/6403 [==============================] - 1s 155us/step\n",
            "[3.2769138134566314e-10, 1.0, 1.0]\n",
            "6\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 380us/step - loss: 1.5558e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.1449e-04 - val_acc: 0.9854 - val_f1_score_macro: 0.9856\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 354us/step - loss: 1.5299e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.2198e-04 - val_acc: 0.9853 - val_f1_score_macro: 0.9855\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 5s 362us/step - loss: 1.4803e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9766e-04 - val_acc: 0.9859 - val_f1_score_macro: 0.9861\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 5s 363us/step - loss: 1.5077e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9605e-04 - val_acc: 0.9859 - val_f1_score_macro: 0.9861\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 348us/step - loss: 1.4687e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0715e-04 - val_acc: 0.9859 - val_f1_score_macro: 0.9859\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 330us/step - loss: 1.4580e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0857e-04 - val_acc: 0.9858 - val_f1_score_macro: 0.9858\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 1.4380e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.1332e-04 - val_acc: 0.9856 - val_f1_score_macro: 0.9858\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 324us/step - loss: 1.4171e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0220e-04 - val_acc: 0.9858 - val_f1_score_macro: 0.9859\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 324us/step - loss: 1.4035e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0417e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9862\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 326us/step - loss: 1.3831e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0001e-04 - val_acc: 0.9858 - val_f1_score_macro: 0.9860\n",
            "6403/6403 [==============================] - 1s 156us/step\n",
            "[2.86075442836758e-10, 1.0, 1.0]\n",
            "7\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 381us/step - loss: 1.3812e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0757e-04 - val_acc: 0.9859 - val_f1_score_macro: 0.9859\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 1.3578e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0042e-04 - val_acc: 0.9863 - val_f1_score_macro: 0.9863\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 330us/step - loss: 1.3387e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0309e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 1.3239e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0347e-04 - val_acc: 0.9859 - val_f1_score_macro: 0.9859\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 1.3136e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0907e-04 - val_acc: 0.9858 - val_f1_score_macro: 0.9859\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 1.2936e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9952e-04 - val_acc: 0.9859 - val_f1_score_macro: 0.9859\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 1.2778e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0207e-04 - val_acc: 0.9858 - val_f1_score_macro: 0.9859\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 1.2744e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0044e-04 - val_acc: 0.9863 - val_f1_score_macro: 0.9863\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 1.2516e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0259e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9863\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 323us/step - loss: 1.2405e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0312e-04 - val_acc: 0.9863 - val_f1_score_macro: 0.9865\n",
            "6403/6403 [==============================] - 1s 155us/step\n",
            "[2.8256727619948773e-10, 1.0, 1.0]\n",
            "8\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 389us/step - loss: 1.2277e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9283e-04 - val_acc: 0.9864 - val_f1_score_macro: 0.9865\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 1.2189e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0973e-04 - val_acc: 0.9859 - val_f1_score_macro: 0.9861\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 326us/step - loss: 1.2033e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0688e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 1.1936e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0215e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 1.1814e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0957e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 1.1717e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0245e-04 - val_acc: 0.9864 - val_f1_score_macro: 0.9864\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 1.1566e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9838e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 1.1503e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0085e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 1.1368e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9412e-04 - val_acc: 0.9864 - val_f1_score_macro: 0.9864\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 1.1278e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9988e-04 - val_acc: 0.9863 - val_f1_score_macro: 0.9863\n",
            "6403/6403 [==============================] - 1s 158us/step\n",
            "[2.590784377750688e-10, 1.0, 1.0]\n",
            "9\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 385us/step - loss: 1.1173e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9975e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 1.1076e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9831e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 326us/step - loss: 1.0971e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0096e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 1.0928e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9494e-04 - val_acc: 0.9864 - val_f1_score_macro: 0.9864\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 1.0759e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0491e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 1.0642e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9865e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 1.0637e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0562e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 326us/step - loss: 1.0558e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0529e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 1.0411e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9936e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 1.0352e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0368e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "6403/6403 [==============================] - 1s 155us/step\n",
            "[2.434890897485594e-10, 1.0, 1.0]\n",
            "10\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 391us/step - loss: 1.0276e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0227e-04 - val_acc: 0.9863 - val_f1_score_macro: 0.9863\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 1.0197e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0268e-04 - val_acc: 0.9863 - val_f1_score_macro: 0.9863\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 1.0119e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9928e-04 - val_acc: 0.9863 - val_f1_score_macro: 0.9863\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 1.0035e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 8.9485e-04 - val_acc: 0.9863 - val_f1_score_macro: 0.9863\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 9.9536e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0393e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 9.8181e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0837e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 9.8705e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0056e-04 - val_acc: 0.9863 - val_f1_score_macro: 0.9863\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 9.7269e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0724e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9861\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 9.6586e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0117e-04 - val_acc: 0.9861 - val_f1_score_macro: 0.9862\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 9.6051e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 9.0017e-04 - val_acc: 0.9863 - val_f1_score_macro: 0.9863\n",
            "6403/6403 [==============================] - 1s 157us/step\n",
            "[2.3432621348627835e-10, 1.0, 1.0]\n",
            "[[6.39623838e-10 1.00000000e+00 1.00000000e+00]\n",
            " [5.16199825e-10 1.00000000e+00 1.00000000e+00]\n",
            " [4.16038407e-10 1.00000000e+00 1.00000000e+00]\n",
            " [3.52724584e-10 1.00000000e+00 1.00000000e+00]\n",
            " [3.27691381e-10 1.00000000e+00 1.00000000e+00]\n",
            " [2.86075443e-10 1.00000000e+00 1.00000000e+00]\n",
            " [2.82567276e-10 1.00000000e+00 1.00000000e+00]\n",
            " [2.59078438e-10 1.00000000e+00 1.00000000e+00]\n",
            " [2.43489090e-10 1.00000000e+00 1.00000000e+00]\n",
            " [2.34326213e-10 1.00000000e+00 1.00000000e+00]]\n",
            "[3.55781449e-10 1.00000000e+00 1.00000000e+00] [1.25563337e-10 0.00000000e+00 0.00000000e+00]\n",
            "3\n",
            "(18734, 512, 2) (18734, 24) (6405, 512, 2) (6405, 24)\n",
            "1\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 390us/step - loss: 9.4992e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.4012e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 9.4359e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3970e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 9.3503e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3708e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 9.2942e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3191e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 9.2057e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.2849e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 9.1599e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.4045e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 9.0960e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3063e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 9.0440e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.2862e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 8.9723e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3039e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 8.9105e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3448e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 156us/step\n",
            "[0.0008677693760523683, 0.9865729898516784, 0.9865920058644255]\n",
            "2\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 389us/step - loss: 8.8614e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3522e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 8.7902e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3434e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 8.7509e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3308e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 8.6617e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.2693e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 8.6211e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.2296e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 330us/step - loss: 8.5878e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.2790e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 330us/step - loss: 8.5139e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.2145e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 8.4694e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.1988e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 8.4121e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.2453e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 8.3583e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3495e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 159us/step\n",
            "[0.0008800616169600257, 0.9864168618266979, 0.9864358778394451]\n",
            "3\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 389us/step - loss: 8.3312e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.2225e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 8.2649e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.2016e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 339us/step - loss: 8.1909e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.2084e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 356us/step - loss: 8.1361e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.1993e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 5s 364us/step - loss: 8.1154e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3477e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 5s 362us/step - loss: 8.0761e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.2765e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 8.0038e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.2246e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 7.9811e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.1466e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 7.9179e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.2085e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 7.8795e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.1315e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 159us/step\n",
            "[0.0008652359606897124, 0.9867291178766588, 0.986748133889406]\n",
            "4\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 390us/step - loss: 7.8290e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.1856e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 7.7852e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.1283e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 7.7397e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.1586e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 7.7070e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.1160e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 7.6581e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.1370e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 7.6203e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.1320e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 7.5688e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.0774e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 336us/step - loss: 7.5037e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.1014e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 334us/step - loss: 7.4911e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.1258e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 333us/step - loss: 7.4579e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.1460e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 160us/step\n",
            "[0.0008675179995576526, 0.9865729898516784, 0.9865920061622161]\n",
            "5\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 404us/step - loss: 7.4085e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.1248e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 7.3791e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.0834e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 7.3449e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.0731e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 7.2892e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.0551e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 7.2560e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.1119e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 330us/step - loss: 7.2205e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.0820e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 7.1757e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.0525e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 7.1474e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.0648e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 7.0780e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.0239e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 7.0790e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.0049e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 156us/step\n",
            "[0.0008681822606338701, 0.9865729898516784, 0.9865920058644255]\n",
            "6\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 400us/step - loss: 7.0372e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.0037e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 6.9782e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.0031e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 6.9640e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9995e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 6.9297e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9689e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 6.8871e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9934e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 6.8517e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.0118e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 6.8229e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.0025e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 6.7964e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9912e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 6.7625e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9877e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 6.7309e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9749e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 159us/step\n",
            "[0.0008676630776167623, 0.9867291178766588, 0.9867481341871965]\n",
            "7\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 406us/step - loss: 6.6943e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9833e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 6.6599e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9431e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 6.6340e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9816e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 6.6000e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9855e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 6.5635e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9765e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 6.5519e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9527e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 6.5001e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9734e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 6.4969e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9436e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 6.4665e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9419e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 6.4197e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9420e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 157us/step\n",
            "[0.0008620986996870529, 0.9867291178766588, 0.986748133889406]\n",
            "8\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 403us/step - loss: 6.3960e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9136e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 6.3754e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9080e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 6.3440e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8955e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 6.3096e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9094e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 6.2854e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9173e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 6.2606e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8742e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 6.2294e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8679e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 6.2093e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8599e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 6.1817e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8577e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 6.1586e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8842e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 158us/step\n",
            "[0.0008625495102928166, 0.9868852459016394, 0.9869042622121771]\n",
            "9\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 410us/step - loss: 6.1275e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9073e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 6.0886e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8784e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 6.0794e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8892e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 6.0355e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9395e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 6.0173e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.9071e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 6.0080e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8669e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 5.9802e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8410e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 5.9543e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8384e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 5.9249e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8375e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 324us/step - loss: 5.9008e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8469e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 159us/step\n",
            "[0.0008641664067832779, 0.9868852459016394, 0.9869042622121771]\n",
            "10\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 409us/step - loss: 5.8811e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8606e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 5.8581e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8328e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 5.8351e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8122e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 334us/step - loss: 5.8114e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8512e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 357us/step - loss: 5.7863e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8279e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 5s 363us/step - loss: 5.7358e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8091e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 5s 365us/step - loss: 5.7460e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8129e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 340us/step - loss: 5.7092e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8171e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 5.6816e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8005e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 324us/step - loss: 5.6790e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 1.8264e-10 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 159us/step\n",
            "[0.0008654336940638719, 0.9868852459016394, 0.9868249587953137]\n",
            "[[8.67769376e-04 9.86572990e-01 9.86592006e-01]\n",
            " [8.80061617e-04 9.86416862e-01 9.86435878e-01]\n",
            " [8.65235961e-04 9.86729118e-01 9.86748134e-01]\n",
            " [8.67518000e-04 9.86572990e-01 9.86592006e-01]\n",
            " [8.68182261e-04 9.86572990e-01 9.86592006e-01]\n",
            " [8.67663078e-04 9.86729118e-01 9.86748134e-01]\n",
            " [8.62098700e-04 9.86729118e-01 9.86748134e-01]\n",
            " [8.62549510e-04 9.86885246e-01 9.86904262e-01]\n",
            " [8.64166407e-04 9.86885246e-01 9.86904262e-01]\n",
            " [8.65433694e-04 9.86885246e-01 9.86824959e-01]]\n",
            "[8.67067860e-04 9.86697892e-01 9.86708978e-01] [4.80293104e-06 1.52973598e-04 1.44897907e-04]\n",
            "[[5.83910964e-03 9.11819255e-01 9.12163534e-01]\n",
            " [7.51323505e-03 8.90912157e-01 8.91067552e-01]\n",
            " [6.45910905e-03 9.07266903e-01 9.06851349e-01]\n",
            " [6.45231639e-03 9.07435508e-01 9.06737462e-01]\n",
            " [6.41741870e-03 9.07941325e-01 9.07320779e-01]\n",
            " [6.40988998e-03 9.07604114e-01 9.07457472e-01]\n",
            " [6.43151689e-03 9.07941325e-01 9.07485591e-01]\n",
            " [6.41088016e-03 9.08615748e-01 9.08236986e-01]\n",
            " [6.39690501e-03 9.08447142e-01 9.08362394e-01]\n",
            " [6.37096421e-03 9.08784353e-01 9.08614781e-01]\n",
            " [6.64976106e-05 9.99062500e-01 9.99062499e-01]\n",
            " [7.24369262e-05 9.99062500e-01 9.98983133e-01]\n",
            " [6.86301257e-05 9.99062500e-01 9.98983133e-01]\n",
            " [7.04518903e-05 9.99062500e-01 9.98983133e-01]\n",
            " [7.09050371e-05 9.99062500e-01 9.98983133e-01]\n",
            " [6.84936308e-05 9.99062500e-01 9.98983133e-01]\n",
            " [6.75326889e-05 9.99062500e-01 9.98983133e-01]\n",
            " [6.94234872e-05 9.99062500e-01 9.98983133e-01]\n",
            " [6.81799411e-05 9.99062500e-01 9.98983133e-01]\n",
            " [6.82935139e-05 9.99062500e-01 9.98983133e-01]\n",
            " [6.39623838e-10 1.00000000e+00 1.00000000e+00]\n",
            " [5.16199825e-10 1.00000000e+00 1.00000000e+00]\n",
            " [4.16038407e-10 1.00000000e+00 1.00000000e+00]\n",
            " [3.52724584e-10 1.00000000e+00 1.00000000e+00]\n",
            " [3.27691381e-10 1.00000000e+00 1.00000000e+00]\n",
            " [2.86075443e-10 1.00000000e+00 1.00000000e+00]\n",
            " [2.82567276e-10 1.00000000e+00 1.00000000e+00]\n",
            " [2.59078438e-10 1.00000000e+00 1.00000000e+00]\n",
            " [2.43489090e-10 1.00000000e+00 1.00000000e+00]\n",
            " [2.34326213e-10 1.00000000e+00 1.00000000e+00]\n",
            " [8.67769376e-04 9.86572990e-01 9.86592006e-01]\n",
            " [8.80061617e-04 9.86416862e-01 9.86435878e-01]\n",
            " [8.65235961e-04 9.86729118e-01 9.86748134e-01]\n",
            " [8.67518000e-04 9.86572990e-01 9.86592006e-01]\n",
            " [8.68182261e-04 9.86572990e-01 9.86592006e-01]\n",
            " [8.67663078e-04 9.86729118e-01 9.86748134e-01]\n",
            " [8.62098700e-04 9.86729118e-01 9.86748134e-01]\n",
            " [8.62549510e-04 9.86885246e-01 9.86904262e-01]\n",
            " [8.64166407e-04 9.86885246e-01 9.86904262e-01]\n",
            " [8.65433694e-04 9.86885246e-01 9.86824959e-01]]\n",
            "[0.00185157 0.97310929 0.97303246] [0.00269524 0.03880644 0.03889881]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tv7O1HexF8Ct",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "np.savetxt(\"results.csv\", np.asarray(results), delimiter=\", \", newline=\"\\r\\n\")\n",
        "files.download('results.csv') \n",
        "summary.append(np.mean(results,axis=0))\n",
        "np.savetxt(\"summary.csv\", np.asarray(summary), delimiter=\", \", newline=\"\\r\\n\")\n",
        "files.download('summary.csv') \n",
        "with open('model.txt','w') as fh:\n",
        "    model.summary(print_fn=lambda x: fh.write('#' + x + '\\r\\n'))\n",
        "    fh.write(str(model.get_config()))\n",
        "files.download('model.txt') "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}