{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cwru.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/fboldt/research/blob/master/cwru.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Con6WhcSFxxm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CWRU files location"
      ]
    },
    {
      "metadata": {
        "id": "uSt7Dc1-nzQn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "aquisitions = {}\n",
        "# Normal\n",
        "aquisitions[\"Normal_0\"] = \"97.mat\"\n",
        "aquisitions[\"Normal_1\"] = \"98.mat\"\n",
        "aquisitions[\"Normal_2\"] = \"99.mat\"\n",
        "aquisitions[\"Normal_3\"] = \"100.mat\"\n",
        "# DE Inner Race 0.007 inches\n",
        "aquisitions[\"DEIR007_0\"] = \"105.mat\"\n",
        "aquisitions[\"DEIR007_1\"] = \"106.mat\"\n",
        "aquisitions[\"DEIR007_2\"] = \"107.mat\"\n",
        "aquisitions[\"DEIR007_3\"] = \"108.mat\"\n",
        "# DE Inner Race 0.014 inches\n",
        "aquisitions[\"DEIR014_0\"] = \"169.mat\"\n",
        "aquisitions[\"DEIR014_1\"] = \"170.mat\"\n",
        "aquisitions[\"DEIR014_2\"] = \"171.mat\"\n",
        "aquisitions[\"DEIR014_3\"] = \"172.mat\"\n",
        "# DE Inner Race 0.021 inches\n",
        "aquisitions[\"DEIR021_0\"] = \"209.mat\"\n",
        "aquisitions[\"DEIR021_1\"] = \"210.mat\"\n",
        "aquisitions[\"DEIR021_2\"] = \"211.mat\"\n",
        "aquisitions[\"DEIR021_3\"] = \"212.mat\"\n",
        "# DE Ball 0.007 inches\n",
        "aquisitions[\"DEB007_0\"] = \"118.mat\"\n",
        "aquisitions[\"DEB007_1\"] = \"119.mat\"\n",
        "aquisitions[\"DEB007_2\"] = \"120.mat\"\n",
        "aquisitions[\"DEB007_3\"] = \"121.mat\"\n",
        "# DE Ball 0.014 inches\n",
        "aquisitions[\"DEB014_0\"] = \"185.mat\"\n",
        "aquisitions[\"DEB014_1\"] = \"186.mat\"\n",
        "aquisitions[\"DEB014_2\"] = \"187.mat\"\n",
        "aquisitions[\"DEB014_3\"] = \"188.mat\"\n",
        "# DE Ball 0.021 inches\n",
        "aquisitions[\"DEB021_0\"] = \"222.mat\"\n",
        "aquisitions[\"DEB021_1\"] = \"223.mat\"\n",
        "aquisitions[\"DEB021_2\"] = \"224.mat\"\n",
        "aquisitions[\"DEB021_3\"] = \"225.mat\"\n",
        "# DE Outer race 0.007 inches centered @6:00\n",
        "aquisitions[\"DEOR007@6_0\"] = \"130.mat\"\n",
        "aquisitions[\"DEOR007@6_1\"] = \"131.mat\"\n",
        "aquisitions[\"DEOR007@6_2\"] = \"132.mat\"\n",
        "aquisitions[\"DEOR007@6_3\"] = \"133.mat\"\n",
        "# DE Outer race 0.014 inches centered @6:00\n",
        "aquisitions[\"DEOR014@6_0\"] = \"197.mat\"\n",
        "aquisitions[\"DEOR014@6_1\"] = \"198.mat\"\n",
        "aquisitions[\"DEOR014@6_2\"] = \"199.mat\"\n",
        "aquisitions[\"DEOR014@6_3\"] = \"200.mat\"\n",
        "# DE Outer race 0.021 inches centered @6:00\n",
        "aquisitions[\"DEOR021@6_0\"] = \"234.mat\"\n",
        "aquisitions[\"DEOR021@6_1\"] = \"235.mat\"\n",
        "aquisitions[\"DEOR021@6_2\"] = \"236.mat\"\n",
        "aquisitions[\"DEOR021@6_3\"] = \"237.mat\"\n",
        "# DE Outer race 0.007 inches centered @3:00\n",
        "aquisitions[\"DEOR007@3_0\"] = \"144.mat\"\n",
        "aquisitions[\"DEOR007@3_1\"] = \"145.mat\"\n",
        "aquisitions[\"DEOR007@3_2\"] = \"146.mat\"\n",
        "aquisitions[\"DEOR007@3_3\"] = \"147.mat\"\n",
        "# DE Outer race 0.021 inches centered @3:00\n",
        "aquisitions[\"DEOR021@3_0\"] = \"246.mat\"\n",
        "aquisitions[\"DEOR021@3_1\"] = \"247.mat\"\n",
        "aquisitions[\"DEOR021@3_2\"] = \"248.mat\"\n",
        "aquisitions[\"DEOR021@3_3\"] = \"249.mat\"\n",
        "# DE Outer race 0.007 inches centered @12:00\n",
        "aquisitions[\"DEOR007@12_0\"] = \"156.mat\"\n",
        "aquisitions[\"DEOR007@12_1\"] = \"158.mat\"\n",
        "aquisitions[\"DEOR007@12_2\"] = \"159.mat\"\n",
        "aquisitions[\"DEOR007@12_3\"] = \"160.mat\"\n",
        "# DE Outer race 0.021 inches centered @12:00\n",
        "aquisitions[\"DEOR021@12_0\"] = \"258.mat\"\n",
        "aquisitions[\"DEOR021@12_1\"] = \"259.mat\"\n",
        "aquisitions[\"DEOR021@12_2\"] = \"260.mat\"\n",
        "aquisitions[\"DEOR021@12_3\"] = \"261.mat\"\n",
        "# FE Inner Race 0.007 inches\n",
        "aquisitions[\"FEIR007_0\"] = \"278.mat\"\n",
        "aquisitions[\"FEIR007_1\"] = \"279.mat\"\n",
        "aquisitions[\"FEIR007_2\"] = \"280.mat\"\n",
        "aquisitions[\"FEIR007_3\"] = \"281.mat\"\n",
        "# FE Inner Race 0.014 inches\n",
        "aquisitions[\"FEIR014_0\"] = \"274.mat\"\n",
        "aquisitions[\"FEIR014_1\"] = \"275.mat\"\n",
        "aquisitions[\"FEIR014_2\"] = \"276.mat\"\n",
        "aquisitions[\"FEIR014_3\"] = \"277.mat\"\n",
        "# FE Inner Race 0.021 inches\n",
        "aquisitions[\"FEIR021_0\"] = \"270.mat\"\n",
        "aquisitions[\"FEIR021_1\"] = \"271.mat\"\n",
        "aquisitions[\"FEIR021_2\"] = \"272.mat\"\n",
        "aquisitions[\"FEIR021_3\"] = \"273.mat\"\n",
        "# FE Ball 0.007 inches\n",
        "aquisitions[\"FEB007_0\"] = \"282.mat\"\n",
        "aquisitions[\"FEB007_1\"] = \"283.mat\"\n",
        "aquisitions[\"FEB007_2\"] = \"284.mat\"\n",
        "aquisitions[\"FEB007_3\"] = \"285.mat\"\n",
        "# FE Ball 0.014 inches\n",
        "aquisitions[\"FEB014_0\"] = \"286.mat\"\n",
        "aquisitions[\"FEB014_1\"] = \"287.mat\"\n",
        "aquisitions[\"FEB014_2\"] = \"288.mat\"\n",
        "aquisitions[\"FEB014_3\"] = \"289.mat\"\n",
        "# FE Ball 0.021 inches\n",
        "aquisitions[\"FEB021_0\"] = \"290.mat\"\n",
        "aquisitions[\"FEB021_1\"] = \"291.mat\"\n",
        "aquisitions[\"FEB021_2\"] = \"292.mat\"\n",
        "aquisitions[\"FEB021_3\"] = \"293.mat\"\n",
        "# FE Outer race 0.007 inches centered @6:00\n",
        "aquisitions[\"FEOR007@6_0\"] = \"294.mat\"\n",
        "aquisitions[\"FEOR007@6_1\"] = \"295.mat\"\n",
        "aquisitions[\"FEOR007@6_2\"] = \"296.mat\"\n",
        "aquisitions[\"FEOR007@6_3\"] = \"297.mat\"\n",
        "# FE Outer race 0.007 inches centered @3:00\n",
        "aquisitions[\"FEOR007@3_0\"] = \"298.mat\"\n",
        "aquisitions[\"FEOR007@3_1\"] = \"299.mat\"\n",
        "aquisitions[\"FEOR007@3_2\"] = \"300.mat\"\n",
        "aquisitions[\"FEOR007@3_3\"] = \"301.mat\"\n",
        "# FE Outer race 0.014 inches centered @3:00\n",
        "aquisitions[\"FEOR014@3_0\"] = \"310.mat\"\n",
        "aquisitions[\"FEOR014@3_1\"] = \"309.mat\"\n",
        "aquisitions[\"FEOR014@3_2\"] = \"311.mat\"\n",
        "aquisitions[\"FEOR014@3_3\"] = \"312.mat\"\n",
        "# FE Outer race 0.007 inches centered @12:00\n",
        "aquisitions[\"FEOR007@12_0\"] = \"302.mat\"\n",
        "aquisitions[\"FEOR007@12_1\"] = \"305.mat\"\n",
        "aquisitions[\"FEOR007@12_2\"] = \"306.mat\"\n",
        "aquisitions[\"FEOR007@12_3\"] = \"307.mat\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R_4WiLNSyrMB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generate a dictionary linking the labels with values to keep consistence"
      ]
    },
    {
      "metadata": {
        "id": "zHDI4LWbyoP6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_labels_dict(aquisitions):\n",
        "  labels_dict = {}\n",
        "  value = 0\n",
        "  for key in aquisitions.keys():\n",
        "    label = key.split('_')[0]\n",
        "    if not label in labels_dict:\n",
        "      labels_dict[label] = value\n",
        "      value += 1\n",
        "  return labels_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Rz0cKigF7q6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert Matlab file into tensors"
      ]
    },
    {
      "metadata": {
        "id": "2tn5IFqkCHQx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "\n",
        "def aquisition2tensor(file_name, sample_size=512):\n",
        "  print(file_name, end=' ')\n",
        "  matlab_file = scipy.io.loadmat(file_name)\n",
        "  DE_time = [key for key in matlab_file if key.endswith(\"DE_time\")][0] #Find the DRIVE END aquisition key name\n",
        "  FE_time = [key for key in matlab_file if key.endswith(\"FE_time\")][0] #Find the FAN END aquisition key name\n",
        "  signal_begin = 0\n",
        "  aquisition_size = max(len(matlab_file[DE_time]),len(matlab_file[FE_time]))\n",
        "  DE_samples = []\n",
        "  FE_samples = []\n",
        "  while signal_begin + sample_size < aquisition_size:\n",
        "    DE_samples.append([item for sublist in matlab_file[DE_time][signal_begin:signal_begin+sample_size] for item in sublist])\n",
        "    FE_samples.append([item for sublist in matlab_file[FE_time][signal_begin:signal_begin+sample_size] for item in sublist])\n",
        "    signal_begin += sample_size\n",
        "  sample_tensor = np.stack([DE_samples,FE_samples],axis=2).astype('float32')\n",
        "  return sample_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x-G4gjyuvA7a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Extract datasets from aquisitions"
      ]
    },
    {
      "metadata": {
        "id": "YC4rhGwWMKT7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def concatenate_datasets(xd,yd,xo,yo):\n",
        "  if xd is None or yd is None:\n",
        "    xd = xo\n",
        "    yd = yo\n",
        "  else:\n",
        "    xd = np.concatenate((xd,xo))\n",
        "    yd = np.concatenate((yd,yo))\n",
        "  return xd,yd\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "def aquisitions_from_load(load, aquisitions, labels_dict,\n",
        "                          url=\"http://csegroups.case.edu/sites/default/files/bearingdatacenter/files/Datafiles/\"\n",
        "                         ):\n",
        "  samples = None\n",
        "  labels = None\n",
        "  for key in aquisitions:\n",
        "    if key.endswith(\"_\"+str(load)):\n",
        "      file_name = aquisitions[key]\n",
        "      urllib.request.urlretrieve(url+file_name, file_name)\n",
        "      aquisition_samples = aquisition2tensor(file_name)\n",
        "      aquisition_labels = np.ones(aquisition_samples.shape[0])*labels_dict[key.split('_')[0]]\n",
        "      samples,labels = concatenate_datasets(samples,labels,aquisition_samples,aquisition_labels)\n",
        "  print(load)\n",
        "  return samples,labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sfwmQa0RJMvb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Exrtract samples"
      ]
    },
    {
      "metadata": {
        "id": "HSASqQsHcgtj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "03e56458-d665-4d8d-bc1e-564f962ab0ac"
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "labels_dict = get_labels_dict(aquisitions)\n",
        "print(labels_dict.keys())\n",
        "\n",
        "x0,y0 = aquisitions_from_load(0,aquisitions,labels_dict)\n",
        "x1,y1 = aquisitions_from_load(1,aquisitions,labels_dict)\n",
        "x2,y2 = aquisitions_from_load(2,aquisitions,labels_dict)\n",
        "x3,y3 = aquisitions_from_load(3,aquisitions,labels_dict)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['Normal', 'DEIR007', 'DEIR014', 'DEIR021', 'DEB007', 'DEB014', 'DEB021', 'DEOR007@6', 'DEOR014@6', 'DEOR021@6', 'DEOR007@3', 'DEOR021@3', 'DEOR007@12', 'DEOR021@12', 'FEIR007', 'FEIR014', 'FEIR021', 'FEB007', 'FEB014', 'FEB021', 'FEOR007@6', 'FEOR007@3', 'FEOR014@3', 'FEOR007@12'])\n",
            "97.mat 105.mat 169.mat 209.mat 118.mat 185.mat 222.mat 130.mat 197.mat 234.mat 144.mat 246.mat 156.mat 258.mat 278.mat 274.mat 270.mat 282.mat 286.mat 290.mat 294.mat 298.mat 310.mat 302.mat 0\n",
            "98.mat 106.mat 170.mat 210.mat 119.mat 186.mat 223.mat 131.mat 198.mat 235.mat 145.mat 247.mat 158.mat 259.mat 279.mat 275.mat 271.mat 283.mat 287.mat 291.mat 295.mat 299.mat 309.mat 305.mat 1\n",
            "99.mat 107.mat 171.mat 211.mat 120.mat 187.mat 224.mat 132.mat 199.mat 236.mat 146.mat 248.mat 159.mat 260.mat 280.mat 276.mat 272.mat 284.mat 288.mat 292.mat 296.mat 300.mat 311.mat 306.mat 2\n",
            "100.mat 108.mat 172.mat 212.mat 121.mat 188.mat 225.mat 133.mat 200.mat 237.mat 147.mat 249.mat 160.mat 261.mat 281.mat 277.mat 273.mat 285.mat 289.mat 293.mat 297.mat 301.mat 312.mat 307.mat 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_QgaHQFpBuDw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define f1-score macro averaged"
      ]
    },
    {
      "metadata": {
        "id": "HdRZ_4pJBzfk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "def f1_score_macro(y_true,y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hPLjBiao2GIK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define architecture model"
      ]
    },
    {
      "metadata": {
        "id": "fpcZrU4Mu9Vk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "b7e8c967-9039-4999-d3be-3506bedd3ab2"
      },
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import Input\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "\n",
        "signal_input = Input(shape=(x0.shape[1],x0.shape[-1]), dtype='float32', name='signal')\n",
        "x = layers.Conv1D(64, 128, activation='relu')(signal_input)\n",
        "x = layers.Flatten()(x)\n",
        "condition_output = layers.Dense(len(labels_dict),activation='softmax',name='condition')(x)\n",
        "\n",
        "model = Model(signal_input, condition_output)\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "signal (InputLayer)          (None, 512, 2)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 385, 64)           16448     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 24640)             0         \n",
            "_________________________________________________________________\n",
            "condition (Dense)            (None, 24)                591384    \n",
            "=================================================================\n",
            "Total params: 607,832\n",
            "Trainable params: 607,832\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y0xe9oYrW1lv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Perform experiments"
      ]
    },
    {
      "metadata": {
        "id": "UU0B-KF-W0eV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17938
        },
        "outputId": "0ef64640-54a0-4778-fe8b-de032fa515e8"
      },
      "cell_type": "code",
      "source": [
        "loads = list(range(4))\n",
        "nrounds = 10\n",
        "results = []\n",
        "summary = []\n",
        "for i,fold in enumerate(loads):\n",
        "  print(fold)\n",
        "  x_test, y_test = eval('x'+str(fold)),eval('y'+str(fold))\n",
        "  y_test = to_categorical(y_test)\n",
        "  x_train,y_train = None,None\n",
        "  for tfold in loads[:i]+loads[i+1:]:\n",
        "    x_train,y_train = concatenate_datasets(x_train,y_train,eval('x'+str(tfold)),eval('y'+str(tfold)))\n",
        "  y_train = to_categorical(y_train)\n",
        "  print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)\n",
        "  for round in range(nrounds):\n",
        "    print(round+1)\n",
        "    model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['accuracy',f1_score_macro])\n",
        "    history = model.fit(x_train,y_train,epochs=10,validation_split=0.33)\n",
        "    results.append(model.evaluate(x_test, y_test))\n",
        "    print(results[-1])\n",
        "  print(np.asarray(results[-nrounds:]))\n",
        "  print(np.mean(results[-nrounds:],axis=0),np.std(results[-nrounds:],axis=0))\n",
        "  summary.append(np.mean(results[-nrounds:],axis=0))\n",
        "\n",
        "print(np.asarray(results))\n",
        "print(np.mean(results,axis=0),np.std(results,axis=0))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "(19208, 512, 2) (19208, 24) (5931, 512, 2) (5931, 24)\n",
            "1\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 6s 491us/step - loss: 0.0101 - acc: 0.8215 - f1_score_macro: 0.8021 - val_loss: 0.0109 - val_acc: 0.8273 - val_f1_score_macro: 0.8216\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 8.3448e-04 - acc: 0.9883 - f1_score_macro: 0.9889 - val_loss: 0.0036 - val_acc: 0.9459 - val_f1_score_macro: 0.9455\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 1.0565e-04 - acc: 0.9984 - f1_score_macro: 0.9985 - val_loss: 0.0031 - val_acc: 0.9503 - val_f1_score_macro: 0.9493\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 327us/step - loss: 5.1333e-05 - acc: 0.9991 - f1_score_macro: 0.9993 - val_loss: 0.0027 - val_acc: 0.9576 - val_f1_score_macro: 0.9574\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 2.9976e-05 - acc: 0.9995 - f1_score_macro: 0.9996 - val_loss: 0.0026 - val_acc: 0.9587 - val_f1_score_macro: 0.9587\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 326us/step - loss: 2.5972e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0032 - val_acc: 0.9497 - val_f1_score_macro: 0.9488\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 2.8225e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0030 - val_acc: 0.9525 - val_f1_score_macro: 0.9517\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 327us/step - loss: 2.8475e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0023 - val_acc: 0.9645 - val_f1_score_macro: 0.9640\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 3.0770e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0024 - val_acc: 0.9634 - val_f1_score_macro: 0.9634\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 2.6558e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0021 - val_acc: 0.9696 - val_f1_score_macro: 0.9691\n",
            "5931/5931 [==============================] - 1s 155us/step\n",
            "[0.004543252367150084, 0.9325577474287641, 0.931203481821804]\n",
            "2\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 4s 341us/step - loss: 3.1140e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0020 - val_acc: 0.9699 - val_f1_score_macro: 0.9698\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 327us/step - loss: 2.6610e-05 - acc: 0.9997 - f1_score_macro: 0.9996 - val_loss: 0.0022 - val_acc: 0.9666 - val_f1_score_macro: 0.9667\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 326us/step - loss: 2.5863e-05 - acc: 0.9997 - f1_score_macro: 0.9997 - val_loss: 0.0023 - val_acc: 0.9648 - val_f1_score_macro: 0.9649\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 1.1927e-05 - acc: 0.9998 - f1_score_macro: 0.9998 - val_loss: 0.0023 - val_acc: 0.9643 - val_f1_score_macro: 0.9640\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 326us/step - loss: 4.6196e-06 - acc: 0.9999 - f1_score_macro: 0.9999 - val_loss: 0.0024 - val_acc: 0.9637 - val_f1_score_macro: 0.9637\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 326us/step - loss: 9.6898e-07 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0025 - val_acc: 0.9618 - val_f1_score_macro: 0.9620\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 325us/step - loss: 1.9505e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0021 - val_acc: 0.9691 - val_f1_score_macro: 0.9693\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 325us/step - loss: 1.4315e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0022 - val_acc: 0.9678 - val_f1_score_macro: 0.9677\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 323us/step - loss: 1.1971e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0021 - val_acc: 0.9683 - val_f1_score_macro: 0.9685\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 324us/step - loss: 1.0272e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0022 - val_acc: 0.9666 - val_f1_score_macro: 0.9671\n",
            "5931/5931 [==============================] - 1s 155us/step\n",
            "[0.003792812642524437, 0.9425054796830215, 0.9424293267548014]\n",
            "3\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 4s 338us/step - loss: 9.2423e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0021 - val_acc: 0.9692 - val_f1_score_macro: 0.9696\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 8.4842e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0020 - val_acc: 0.9703 - val_f1_score_macro: 0.9705\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 7.8149e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9708 - val_f1_score_macro: 0.9712\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 7.3341e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0020 - val_acc: 0.9699 - val_f1_score_macro: 0.9701\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 327us/step - loss: 6.8741e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0020 - val_acc: 0.9705 - val_f1_score_macro: 0.9710\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 327us/step - loss: 6.4759e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0020 - val_acc: 0.9711 - val_f1_score_macro: 0.9716\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 6.1562e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0021 - val_acc: 0.9692 - val_f1_score_macro: 0.9694\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 325us/step - loss: 5.8143e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0020 - val_acc: 0.9702 - val_f1_score_macro: 0.9704\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 334us/step - loss: 5.5806e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9718 - val_f1_score_macro: 0.9716\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 5.3638e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0020 - val_acc: 0.9718 - val_f1_score_macro: 0.9715\n",
            "5931/5931 [==============================] - 1s 159us/step\n",
            "[0.003750087263711786, 0.9438543247344461, 0.9434769568847697]\n",
            "4\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 4s 346us/step - loss: 5.1237e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9714 - val_f1_score_macro: 0.9714\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 327us/step - loss: 4.9206e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9727 - val_f1_score_macro: 0.9726\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 4.6923e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9719 - val_f1_score_macro: 0.9719\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 4.5881e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9713 - val_f1_score_macro: 0.9715\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 4.4513e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9718 - val_f1_score_macro: 0.9717\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 4.3041e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0020 - val_acc: 0.9708 - val_f1_score_macro: 0.9710\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 4.1392e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9724 - val_f1_score_macro: 0.9717\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 4.0495e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0020 - val_acc: 0.9711 - val_f1_score_macro: 0.9712\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 3.9133e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9716 - val_f1_score_macro: 0.9713\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 3.8045e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0020 - val_acc: 0.9714 - val_f1_score_macro: 0.9712\n",
            "5931/5931 [==============================] - 1s 160us/step\n",
            "[0.0036961716747227675, 0.9450345641544428, 0.9448360059780287]\n",
            "5\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 4s 348us/step - loss: 3.6835e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0020 - val_acc: 0.9707 - val_f1_score_macro: 0.9708\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 325us/step - loss: 3.6080e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9726 - val_f1_score_macro: 0.9723\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 339us/step - loss: 3.4857e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0020 - val_acc: 0.9714 - val_f1_score_macro: 0.9712\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 5s 353us/step - loss: 3.4379e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9726 - val_f1_score_macro: 0.9723\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 5s 359us/step - loss: 3.3534e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9726 - val_f1_score_macro: 0.9724\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 5s 358us/step - loss: 3.2896e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9718 - val_f1_score_macro: 0.9716\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 3.1957e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9719 - val_f1_score_macro: 0.9716\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 3.1241e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9730 - val_f1_score_macro: 0.9726\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 336us/step - loss: 3.0641e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9729 - val_f1_score_macro: 0.9725\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 335us/step - loss: 3.0097e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9726 - val_f1_score_macro: 0.9725\n",
            "5931/5931 [==============================] - 1s 157us/step\n",
            "[0.003585184586915132, 0.9462148035744394, 0.9463651430705329]\n",
            "6\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 5s 354us/step - loss: 2.9276e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9721 - val_f1_score_macro: 0.9720\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 334us/step - loss: 2.8790e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9724 - val_f1_score_macro: 0.9724\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 335us/step - loss: 2.8060e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9732 - val_f1_score_macro: 0.9728\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 334us/step - loss: 2.7880e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9724 - val_f1_score_macro: 0.9723\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 2.7231e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9732 - val_f1_score_macro: 0.9730\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 2.6780e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9729 - val_f1_score_macro: 0.9727\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 2.6338e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9733 - val_f1_score_macro: 0.9729\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 2.5869e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9737 - val_f1_score_macro: 0.9733\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 334us/step - loss: 2.5365e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9738 - val_f1_score_macro: 0.9735\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 2.5066e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9729 - val_f1_score_macro: 0.9726\n",
            "5931/5931 [==============================] - 1s 155us/step\n",
            "[0.0035480689702366143, 0.9472264373630079, 0.9467602832545279]\n",
            "7\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 5s 362us/step - loss: 2.4551e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9729 - val_f1_score_macro: 0.9724\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 2.4209e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9732 - val_f1_score_macro: 0.9728\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 2.3674e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9719 - val_f1_score_macro: 0.9718\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 2.3507e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9727 - val_f1_score_macro: 0.9724\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 335us/step - loss: 2.3057e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9733 - val_f1_score_macro: 0.9731\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 2.2714e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9730 - val_f1_score_macro: 0.9728\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 2.2352e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9732 - val_f1_score_macro: 0.9730\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 335us/step - loss: 2.2097e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9724 - val_f1_score_macro: 0.9725\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 2.1758e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9727 - val_f1_score_macro: 0.9726\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 2.1441e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9733 - val_f1_score_macro: 0.9731\n",
            "5931/5931 [==============================] - 1s 158us/step\n",
            "[0.0035581917714715386, 0.947395042994436, 0.9472153323875714]\n",
            "8\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 5s 352us/step - loss: 2.1181e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9722 - val_f1_score_macro: 0.9722\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 2.0892e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9730 - val_f1_score_macro: 0.9729\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 2.0588e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9727 - val_f1_score_macro: 0.9726\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 334us/step - loss: 2.0373e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9730 - val_f1_score_macro: 0.9728\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 2.0047e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9724 - val_f1_score_macro: 0.9724\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 1.9860e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9726 - val_f1_score_macro: 0.9728\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 1.9550e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9737 - val_f1_score_macro: 0.9734\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 335us/step - loss: 1.9354e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9737 - val_f1_score_macro: 0.9736\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 334us/step - loss: 1.9125e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9735 - val_f1_score_macro: 0.9734\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 1.8878e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9737 - val_f1_score_macro: 0.9736\n",
            "5931/5931 [==============================] - 1s 158us/step\n",
            "[0.0035472317352598826, 0.9477322542572922, 0.9473252269916602]\n",
            "9\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 5s 360us/step - loss: 1.8687e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9732 - val_f1_score_macro: 0.9731\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 332us/step - loss: 1.8357e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9737 - val_f1_score_macro: 0.9734\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 334us/step - loss: 1.8273e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9737 - val_f1_score_macro: 0.9734\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 1.8048e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9738 - val_f1_score_macro: 0.9736\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 1.7848e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9730 - val_f1_score_macro: 0.9728\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 329us/step - loss: 1.7591e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9729 - val_f1_score_macro: 0.9728\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 330us/step - loss: 1.7464e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9735 - val_f1_score_macro: 0.9733\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 341us/step - loss: 1.7160e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9733 - val_f1_score_macro: 0.9732\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 1.7080e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9733 - val_f1_score_macro: 0.9731\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 1.6880e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9735 - val_f1_score_macro: 0.9732\n",
            "5931/5931 [==============================] - 1s 154us/step\n",
            "[0.003534683197696443, 0.9475636486258641, 0.9474659430761599]\n",
            "10\n",
            "Train on 12869 samples, validate on 6339 samples\n",
            "Epoch 1/10\n",
            "12869/12869 [==============================] - 5s 360us/step - loss: 1.6764e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9730 - val_f1_score_macro: 0.9728\n",
            "Epoch 2/10\n",
            "12869/12869 [==============================] - 4s 334us/step - loss: 1.6452e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9743 - val_f1_score_macro: 0.9740\n",
            "Epoch 3/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 1.6317e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9737 - val_f1_score_macro: 0.9736\n",
            "Epoch 4/10\n",
            "12869/12869 [==============================] - 4s 336us/step - loss: 1.6240e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9732 - val_f1_score_macro: 0.9730\n",
            "Epoch 5/10\n",
            "12869/12869 [==============================] - 4s 333us/step - loss: 1.6060e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9735 - val_f1_score_macro: 0.9734\n",
            "Epoch 6/10\n",
            "12869/12869 [==============================] - 4s 331us/step - loss: 1.5910e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9738 - val_f1_score_macro: 0.9735\n",
            "Epoch 7/10\n",
            "12869/12869 [==============================] - 4s 327us/step - loss: 1.5744e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9735 - val_f1_score_macro: 0.9733\n",
            "Epoch 8/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 1.5559e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9741 - val_f1_score_macro: 0.9736\n",
            "Epoch 9/10\n",
            "12869/12869 [==============================] - 4s 328us/step - loss: 1.5385e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9743 - val_f1_score_macro: 0.9740\n",
            "Epoch 10/10\n",
            "12869/12869 [==============================] - 4s 326us/step - loss: 1.5323e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9737 - val_f1_score_macro: 0.9734\n",
            "5931/5931 [==============================] - 1s 158us/step\n",
            "[0.003481278949259262, 0.9480694655201484, 0.9480779241337741]\n",
            "[[0.00454325 0.93255775 0.93120348]\n",
            " [0.00379281 0.94250548 0.94242933]\n",
            " [0.00375009 0.94385432 0.94347696]\n",
            " [0.00369617 0.94503456 0.94483601]\n",
            " [0.00358518 0.9462148  0.94636514]\n",
            " [0.00354807 0.94722644 0.94676028]\n",
            " [0.00355819 0.94739504 0.94721533]\n",
            " [0.00354723 0.94773225 0.94732523]\n",
            " [0.00353468 0.94756365 0.94746594]\n",
            " [0.00348128 0.94806947 0.94807792]]\n",
            "[0.0037037  0.94481538 0.94451556] [0.00029613 0.0044456  0.00477266]\n",
            "1\n",
            "(18739, 512, 2) (18739, 24) (6400, 512, 2) (6400, 24)\n",
            "1\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 4s 354us/step - loss: 3.6311e-04 - acc: 0.9943 - f1_score_macro: 0.9944 - val_loss: 0.0023 - val_acc: 0.9660 - val_f1_score_macro: 0.9661\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 325us/step - loss: 7.9731e-05 - acc: 0.9988 - f1_score_macro: 0.9988 - val_loss: 0.0029 - val_acc: 0.9567 - val_f1_score_macro: 0.9564\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 325us/step - loss: 1.9170e-05 - acc: 0.9998 - f1_score_macro: 0.9998 - val_loss: 0.0030 - val_acc: 0.9510 - val_f1_score_macro: 0.9508\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 3.1950e-06 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0027 - val_acc: 0.9601 - val_f1_score_macro: 0.9593\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 2.2313e-07 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0026 - val_acc: 0.9639 - val_f1_score_macro: 0.9637\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 9.1162e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0023 - val_acc: 0.9649 - val_f1_score_macro: 0.9642\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 3.1537e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0020 - val_acc: 0.9698 - val_f1_score_macro: 0.9697\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 336us/step - loss: 1.9126e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0022 - val_acc: 0.9670 - val_f1_score_macro: 0.9672\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 339us/step - loss: 1.5122e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0022 - val_acc: 0.9681 - val_f1_score_macro: 0.9682\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 349us/step - loss: 1.3136e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0020 - val_acc: 0.9696 - val_f1_score_macro: 0.9699\n",
            "6400/6400 [==============================] - 1s 162us/step\n",
            "[6.496065782170102e-05, 0.9990625, 0.9990500983595848]\n",
            "2\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 368us/step - loss: 1.0722e-09 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0021 - val_acc: 0.9673 - val_f1_score_macro: 0.9678\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 9.7324e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0020 - val_acc: 0.9686 - val_f1_score_macro: 0.9690\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 341us/step - loss: 8.7936e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0020 - val_acc: 0.9698 - val_f1_score_macro: 0.9702\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 350us/step - loss: 8.0640e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9701 - val_f1_score_macro: 0.9706\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 346us/step - loss: 7.4292e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9699 - val_f1_score_macro: 0.9701\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 347us/step - loss: 7.0427e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9709 - val_f1_score_macro: 0.9713\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 6.5319e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9706 - val_f1_score_macro: 0.9711\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 6.0363e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9698 - val_f1_score_macro: 0.9701\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 335us/step - loss: 5.7396e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9702 - val_f1_score_macro: 0.9707\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 5.4705e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0021 - val_acc: 0.9685 - val_f1_score_macro: 0.9688\n",
            "6400/6400 [==============================] - 1s 157us/step\n",
            "[6.363073547403244e-05, 0.99921875, 0.999139384329319]\n",
            "3\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 363us/step - loss: 5.2289e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9706 - val_f1_score_macro: 0.9708\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 4.9826e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0020 - val_acc: 0.9698 - val_f1_score_macro: 0.9701\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 4.7163e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9701 - val_f1_score_macro: 0.9707\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 4.5639e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9712 - val_f1_score_macro: 0.9716\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 328us/step - loss: 4.3654e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9706 - val_f1_score_macro: 0.9709\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 338us/step - loss: 4.2010e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9701 - val_f1_score_macro: 0.9705\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 4.0970e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9704 - val_f1_score_macro: 0.9707\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 3.9983e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9732 - val_f1_score_macro: 0.9737\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 3.8372e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9720 - val_f1_score_macro: 0.9726\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 3.6679e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9702 - val_f1_score_macro: 0.9705\n",
            "6400/6400 [==============================] - 1s 159us/step\n",
            "[6.428389527894734e-05, 0.99921875, 0.999206348657608]\n",
            "4\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 366us/step - loss: 3.6026e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9730 - val_f1_score_macro: 0.9736\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 3.4755e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9701 - val_f1_score_macro: 0.9708\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 3.4058e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9719 - val_f1_score_macro: 0.9722\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 3.2999e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9719 - val_f1_score_macro: 0.9722\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 3.2640e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9717 - val_f1_score_macro: 0.9720\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 335us/step - loss: 3.1497e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9717 - val_f1_score_macro: 0.9724\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 336us/step - loss: 3.1006e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9706 - val_f1_score_macro: 0.9711\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 3.0310e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9706 - val_f1_score_macro: 0.9710\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 2.9546e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9706 - val_f1_score_macro: 0.9710\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 337us/step - loss: 2.8779e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9711 - val_f1_score_macro: 0.9713\n",
            "6400/6400 [==============================] - 1s 159us/step\n",
            "[6.493214166135155e-05, 0.99921875, 0.999139384329319]\n",
            "5\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 368us/step - loss: 2.8189e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9707 - val_f1_score_macro: 0.9712\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 2.7523e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9706 - val_f1_score_macro: 0.9710\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 2.7174e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9720 - val_f1_score_macro: 0.9724\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 2.6487e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9725 - val_f1_score_macro: 0.9729\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 2.6021e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9712 - val_f1_score_macro: 0.9716\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 336us/step - loss: 2.5441e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9715 - val_f1_score_macro: 0.9720\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 2.5191e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9717 - val_f1_score_macro: 0.9721\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 2.4476e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9735 - val_f1_score_macro: 0.9738\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 2.4309e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9717 - val_f1_score_macro: 0.9721\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 2.3707e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9727 - val_f1_score_macro: 0.9733\n",
            "6400/6400 [==============================] - 1s 163us/step\n",
            "[6.392735192267733e-05, 0.99921875, 0.9992187497019768]\n",
            "6\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 370us/step - loss: 2.3464e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9723 - val_f1_score_macro: 0.9727\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 2.2886e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9723 - val_f1_score_macro: 0.9727\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 2.2562e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9719 - val_f1_score_macro: 0.9722\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 2.2246e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9735 - val_f1_score_macro: 0.9738\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 2.2012e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9725 - val_f1_score_macro: 0.9729\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 2.1481e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9723 - val_f1_score_macro: 0.9729\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 2.1209e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9727 - val_f1_score_macro: 0.9730\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 2.0879e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9727 - val_f1_score_macro: 0.9731\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 2.0680e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9738 - val_f1_score_macro: 0.9743\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 336us/step - loss: 2.0357e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9732 - val_f1_score_macro: 0.9734\n",
            "6400/6400 [==============================] - 1s 156us/step\n",
            "[6.347893540212795e-05, 0.99921875, 0.9992187497019768]\n",
            "7\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 371us/step - loss: 2.0048e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9727 - val_f1_score_macro: 0.9731\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 1.9713e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9719 - val_f1_score_macro: 0.9723\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 1.9548e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9735 - val_f1_score_macro: 0.9738\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 1.9284e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9738 - val_f1_score_macro: 0.9741\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 1.8966e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9736 - val_f1_score_macro: 0.9738\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 1.8678e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9725 - val_f1_score_macro: 0.9729\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 1.8512e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9736 - val_f1_score_macro: 0.9738\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 1.8239e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9728 - val_f1_score_macro: 0.9731\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 1.8057e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9736 - val_f1_score_macro: 0.9739\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 1.7777e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9738 - val_f1_score_macro: 0.9742\n",
            "6400/6400 [==============================] - 1s 156us/step\n",
            "[6.308896133270795e-05, 0.99921875, 0.9992187497019768]\n",
            "8\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 381us/step - loss: 1.7629e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9728 - val_f1_score_macro: 0.9733\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 1.7446e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9740 - val_f1_score_macro: 0.9742\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 1.7224e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9735 - val_f1_score_macro: 0.9739\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 1.6987e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9740 - val_f1_score_macro: 0.9741\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 1.6800e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9740 - val_f1_score_macro: 0.9743\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 1.6601e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9741 - val_f1_score_macro: 0.9744\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 1.6455e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9736 - val_f1_score_macro: 0.9740\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 337us/step - loss: 1.6212e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9748 - val_f1_score_macro: 0.9750\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 1.6077e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9746 - val_f1_score_macro: 0.9748\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 335us/step - loss: 1.5930e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9745 - val_f1_score_macro: 0.9747\n",
            "6400/6400 [==============================] - 1s 157us/step\n",
            "[6.437851338888277e-05, 0.99921875, 0.9992187497019768]\n",
            "9\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 371us/step - loss: 1.5779e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9740 - val_f1_score_macro: 0.9742\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 330us/step - loss: 1.5593e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9741 - val_f1_score_macro: 0.9745\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 329us/step - loss: 1.5429e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9736 - val_f1_score_macro: 0.9739\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 340us/step - loss: 1.5229e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0016 - val_acc: 0.9748 - val_f1_score_macro: 0.9751\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 353us/step - loss: 1.5088e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9738 - val_f1_score_macro: 0.9741\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 353us/step - loss: 1.4916e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9738 - val_f1_score_macro: 0.9741\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 353us/step - loss: 1.4847e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9746 - val_f1_score_macro: 0.9749\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 1.4642e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0016 - val_acc: 0.9751 - val_f1_score_macro: 0.9755\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 1.4540e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0016 - val_acc: 0.9751 - val_f1_score_macro: 0.9755\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 1.4332e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9736 - val_f1_score_macro: 0.9739\n",
            "6400/6400 [==============================] - 1s 162us/step\n",
            "[6.37578996154348e-05, 0.99921875, 0.9992187497019768]\n",
            "10\n",
            "Train on 12555 samples, validate on 6184 samples\n",
            "Epoch 1/10\n",
            "12555/12555 [==============================] - 5s 382us/step - loss: 1.4254e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9738 - val_f1_score_macro: 0.9741\n",
            "Epoch 2/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 1.4059e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9746 - val_f1_score_macro: 0.9749\n",
            "Epoch 3/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 1.4024e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9748 - val_f1_score_macro: 0.9750\n",
            "Epoch 4/10\n",
            "12555/12555 [==============================] - 4s 334us/step - loss: 1.3848e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9746 - val_f1_score_macro: 0.9749\n",
            "Epoch 5/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 1.3736e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9746 - val_f1_score_macro: 0.9749\n",
            "Epoch 6/10\n",
            "12555/12555 [==============================] - 4s 332us/step - loss: 1.3609e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0016 - val_acc: 0.9751 - val_f1_score_macro: 0.9753\n",
            "Epoch 7/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 1.3481e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9746 - val_f1_score_macro: 0.9748\n",
            "Epoch 8/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 1.3376e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0016 - val_acc: 0.9751 - val_f1_score_macro: 0.9753\n",
            "Epoch 9/10\n",
            "12555/12555 [==============================] - 4s 333us/step - loss: 1.3287e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0016 - val_acc: 0.9751 - val_f1_score_macro: 0.9753\n",
            "Epoch 10/10\n",
            "12555/12555 [==============================] - 4s 331us/step - loss: 1.3083e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9746 - val_f1_score_macro: 0.9748\n",
            "6400/6400 [==============================] - 1s 158us/step\n",
            "[6.447403179816907e-05, 0.99921875, 0.9992187497019768]\n",
            "[[6.49606578e-05 9.99062500e-01 9.99050098e-01]\n",
            " [6.36307355e-05 9.99218750e-01 9.99139384e-01]\n",
            " [6.42838953e-05 9.99218750e-01 9.99206349e-01]\n",
            " [6.49321417e-05 9.99218750e-01 9.99139384e-01]\n",
            " [6.39273519e-05 9.99218750e-01 9.99218750e-01]\n",
            " [6.34789354e-05 9.99218750e-01 9.99218750e-01]\n",
            " [6.30889613e-05 9.99218750e-01 9.99218750e-01]\n",
            " [6.43785134e-05 9.99218750e-01 9.99218750e-01]\n",
            " [6.37578996e-05 9.99218750e-01 9.99218750e-01]\n",
            " [6.44740318e-05 9.99218750e-01 9.99218750e-01]]\n",
            "[6.40913124e-05 9.99203125e-01 9.99184771e-01] [5.88106580e-07 4.68750000e-05 5.44513804e-05]\n",
            "2\n",
            "(18736, 512, 2) (18736, 24) (6403, 512, 2) (6403, 24)\n",
            "1\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 382us/step - loss: 4.5535e-05 - acc: 0.9994 - f1_score_macro: 0.9994 - val_loss: 0.0017 - val_acc: 0.9761 - val_f1_score_macro: 0.9760\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 334us/step - loss: 2.2883e-05 - acc: 0.9996 - f1_score_macro: 0.9996 - val_loss: 0.0016 - val_acc: 0.9762 - val_f1_score_macro: 0.9764\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 335us/step - loss: 7.6629e-06 - acc: 0.9998 - f1_score_macro: 0.9998 - val_loss: 0.0015 - val_acc: 0.9774 - val_f1_score_macro: 0.9771\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 333us/step - loss: 8.0654e-07 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0023 - val_acc: 0.9656 - val_f1_score_macro: 0.9656\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 338us/step - loss: 4.3156e-06 - acc: 0.9999 - f1_score_macro: 0.9999 - val_loss: 0.0019 - val_acc: 0.9710 - val_f1_score_macro: 0.9706\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 335us/step - loss: 8.9418e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9709 - val_f1_score_macro: 0.9707\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 334us/step - loss: 5.0565e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9722 - val_f1_score_macro: 0.9717\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 334us/step - loss: 4.3403e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9728 - val_f1_score_macro: 0.9726\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 333us/step - loss: 3.8587e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9733 - val_f1_score_macro: 0.9729\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 3.6262e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9732 - val_f1_score_macro: 0.9726\n",
            "6403/6403 [==============================] - 1s 158us/step\n",
            "[3.273363210949637e-08, 1.0, 1.0]\n",
            "2\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 383us/step - loss: 3.4247e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9728 - val_f1_score_macro: 0.9725\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 336us/step - loss: 3.1991e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9730 - val_f1_score_macro: 0.9727\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 334us/step - loss: 3.0111e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0019 - val_acc: 0.9720 - val_f1_score_macro: 0.9719\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 337us/step - loss: 2.8781e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9723 - val_f1_score_macro: 0.9723\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 335us/step - loss: 2.8002e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9730 - val_f1_score_macro: 0.9729\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 333us/step - loss: 2.6610e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9732 - val_f1_score_macro: 0.9729\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 336us/step - loss: 2.6395e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9732 - val_f1_score_macro: 0.9729\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 337us/step - loss: 2.4340e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9735 - val_f1_score_macro: 0.9732\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 337us/step - loss: 2.4494e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9730 - val_f1_score_macro: 0.9728\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 335us/step - loss: 2.3633e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9736 - val_f1_score_macro: 0.9734\n",
            "6403/6403 [==============================] - 1s 157us/step\n",
            "[1.5846115373729097e-08, 1.0, 1.0]\n",
            "3\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 384us/step - loss: 2.2406e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9736 - val_f1_score_macro: 0.9736\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 337us/step - loss: 2.2233e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9728 - val_f1_score_macro: 0.9727\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 333us/step - loss: 2.1606e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9732 - val_f1_score_macro: 0.9732\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 333us/step - loss: 2.0391e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9741 - val_f1_score_macro: 0.9740\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 2.0628e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9728 - val_f1_score_macro: 0.9729\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 335us/step - loss: 1.9884e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9727 - val_f1_score_macro: 0.9726\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 336us/step - loss: 1.9392e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9733 - val_f1_score_macro: 0.9732\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 333us/step - loss: 1.9196e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9744 - val_f1_score_macro: 0.9741\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 337us/step - loss: 1.8602e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9733 - val_f1_score_macro: 0.9732\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 337us/step - loss: 1.8121e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9736 - val_f1_score_macro: 0.9736\n",
            "6403/6403 [==============================] - 1s 163us/step\n",
            "[1.1153658765141347e-08, 1.0, 1.0]\n",
            "4\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 387us/step - loss: 1.8163e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9732 - val_f1_score_macro: 0.9731\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 335us/step - loss: 1.7773e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9746 - val_f1_score_macro: 0.9746\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 335us/step - loss: 1.7277e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9738 - val_f1_score_macro: 0.9736\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 332us/step - loss: 1.6810e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9733 - val_f1_score_macro: 0.9733\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 334us/step - loss: 1.6817e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9733 - val_f1_score_macro: 0.9733\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 336us/step - loss: 1.6458e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9740 - val_f1_score_macro: 0.9738\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 1.6015e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9746 - val_f1_score_macro: 0.9747\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 333us/step - loss: 1.6113e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9736 - val_f1_score_macro: 0.9736\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 334us/step - loss: 1.5655e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9736 - val_f1_score_macro: 0.9738\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 332us/step - loss: 1.5437e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9738 - val_f1_score_macro: 0.9737\n",
            "6403/6403 [==============================] - 1s 159us/step\n",
            "[8.715341545750076e-09, 1.0, 1.0]\n",
            "5\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 387us/step - loss: 1.5205e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9741 - val_f1_score_macro: 0.9740\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 334us/step - loss: 1.4947e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9733 - val_f1_score_macro: 0.9734\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 333us/step - loss: 1.4637e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9735 - val_f1_score_macro: 0.9734\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 332us/step - loss: 1.4455e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9743 - val_f1_score_macro: 0.9740\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 335us/step - loss: 1.4406e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9741 - val_f1_score_macro: 0.9742\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 337us/step - loss: 1.4177e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9736 - val_f1_score_macro: 0.9736\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 335us/step - loss: 1.3937e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9741 - val_f1_score_macro: 0.9742\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 338us/step - loss: 1.3710e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9743 - val_f1_score_macro: 0.9742\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 336us/step - loss: 1.3643e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9736 - val_f1_score_macro: 0.9737\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 334us/step - loss: 1.3554e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9736 - val_f1_score_macro: 0.9737\n",
            "6403/6403 [==============================] - 1s 161us/step\n",
            "[7.0738240457786975e-09, 1.0, 1.0]\n",
            "6\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 389us/step - loss: 1.3228e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9744 - val_f1_score_macro: 0.9744\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 333us/step - loss: 1.3204e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9741 - val_f1_score_macro: 0.9743\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 334us/step - loss: 1.2863e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9746 - val_f1_score_macro: 0.9744\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 338us/step - loss: 1.2734e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9740 - val_f1_score_macro: 0.9740\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 355us/step - loss: 1.2672e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9733 - val_f1_score_macro: 0.9735\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 5s 364us/step - loss: 1.2444e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9738 - val_f1_score_macro: 0.9738\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 5s 365us/step - loss: 1.2378e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9743 - val_f1_score_macro: 0.9745\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 350us/step - loss: 1.2228e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9744 - val_f1_score_macro: 0.9742\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 336us/step - loss: 1.2098e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9744 - val_f1_score_macro: 0.9742\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 338us/step - loss: 1.2002e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9738 - val_f1_score_macro: 0.9741\n",
            "6403/6403 [==============================] - 1s 163us/step\n",
            "[6.034662121444497e-09, 1.0, 1.0]\n",
            "7\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 396us/step - loss: 1.1839e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9738 - val_f1_score_macro: 0.9740\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 333us/step - loss: 1.1799e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9746 - val_f1_score_macro: 0.9745\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 1.1599e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9746 - val_f1_score_macro: 0.9745\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 332us/step - loss: 1.1509e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9744 - val_f1_score_macro: 0.9742\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 1.1433e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9743 - val_f1_score_macro: 0.9742\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 1.1289e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9740 - val_f1_score_macro: 0.9740\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 1.1200e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9736 - val_f1_score_macro: 0.9738\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 1.1069e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9748 - val_f1_score_macro: 0.9745\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 1.0970e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9744 - val_f1_score_macro: 0.9742\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 1.0886e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9744 - val_f1_score_macro: 0.9742\n",
            "6403/6403 [==============================] - 1s 155us/step\n",
            "[5.431994111215913e-09, 1.0, 1.0]\n",
            "8\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 383us/step - loss: 1.0788e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9741 - val_f1_score_macro: 0.9739\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 1.0694e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9741 - val_f1_score_macro: 0.9738\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 332us/step - loss: 1.0563e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9738 - val_f1_score_macro: 0.9738\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 333us/step - loss: 1.0501e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9740 - val_f1_score_macro: 0.9739\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 331us/step - loss: 1.0376e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9735 - val_f1_score_macro: 0.9737\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 326us/step - loss: 1.0349e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9743 - val_f1_score_macro: 0.9740\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 1.0225e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9746 - val_f1_score_macro: 0.9743\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 1.0141e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9746 - val_f1_score_macro: 0.9743\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 1.0070e-10 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9736 - val_f1_score_macro: 0.9736\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 9.9827e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9743 - val_f1_score_macro: 0.9740\n",
            "6403/6403 [==============================] - 1s 158us/step\n",
            "[4.89476752503437e-09, 1.0, 1.0]\n",
            "9\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 387us/step - loss: 9.8922e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9749 - val_f1_score_macro: 0.9746\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 330us/step - loss: 9.8271e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9749 - val_f1_score_macro: 0.9747\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 9.7309e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9746 - val_f1_score_macro: 0.9744\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 9.6229e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9741 - val_f1_score_macro: 0.9739\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 9.6035e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9743 - val_f1_score_macro: 0.9741\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 9.5354e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9741 - val_f1_score_macro: 0.9739\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 9.4329e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9738 - val_f1_score_macro: 0.9736\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 9.3432e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9748 - val_f1_score_macro: 0.9746\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 9.3333e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9741 - val_f1_score_macro: 0.9739\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 9.2356e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9743 - val_f1_score_macro: 0.9741\n",
            "6403/6403 [==============================] - 1s 159us/step\n",
            "[4.478714469063438e-09, 1.0, 1.0]\n",
            "10\n",
            "Train on 12553 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12553/12553 [==============================] - 5s 386us/step - loss: 9.1893e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9743 - val_f1_score_macro: 0.9741\n",
            "Epoch 2/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 9.1088e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9744 - val_f1_score_macro: 0.9742\n",
            "Epoch 3/10\n",
            "12553/12553 [==============================] - 4s 326us/step - loss: 9.0454e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9746 - val_f1_score_macro: 0.9744\n",
            "Epoch 4/10\n",
            "12553/12553 [==============================] - 4s 328us/step - loss: 8.9691e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9741 - val_f1_score_macro: 0.9739\n",
            "Epoch 5/10\n",
            "12553/12553 [==============================] - 4s 325us/step - loss: 8.9230e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9743 - val_f1_score_macro: 0.9741\n",
            "Epoch 6/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 8.8627e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9741 - val_f1_score_macro: 0.9739\n",
            "Epoch 7/10\n",
            "12553/12553 [==============================] - 4s 329us/step - loss: 8.7894e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9746 - val_f1_score_macro: 0.9744\n",
            "Epoch 8/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 8.7270e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0017 - val_acc: 0.9748 - val_f1_score_macro: 0.9746\n",
            "Epoch 9/10\n",
            "12553/12553 [==============================] - 4s 327us/step - loss: 8.6171e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9735 - val_f1_score_macro: 0.9735\n",
            "Epoch 10/10\n",
            "12553/12553 [==============================] - 4s 326us/step - loss: 8.5939e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 0.0018 - val_acc: 0.9744 - val_f1_score_macro: 0.9742\n",
            "6403/6403 [==============================] - 1s 157us/step\n",
            "[4.064144509608364e-09, 1.0, 1.0]\n",
            "[[3.27336321e-08 1.00000000e+00 1.00000000e+00]\n",
            " [1.58461154e-08 1.00000000e+00 1.00000000e+00]\n",
            " [1.11536588e-08 1.00000000e+00 1.00000000e+00]\n",
            " [8.71534155e-09 1.00000000e+00 1.00000000e+00]\n",
            " [7.07382405e-09 1.00000000e+00 1.00000000e+00]\n",
            " [6.03466212e-09 1.00000000e+00 1.00000000e+00]\n",
            " [5.43199411e-09 1.00000000e+00 1.00000000e+00]\n",
            " [4.89476753e-09 1.00000000e+00 1.00000000e+00]\n",
            " [4.47871447e-09 1.00000000e+00 1.00000000e+00]\n",
            " [4.06414451e-09 1.00000000e+00 1.00000000e+00]]\n",
            "[1.00426855e-08 1.00000000e+00 1.00000000e+00] [8.31200102e-09 0.00000000e+00 0.00000000e+00]\n",
            "3\n",
            "(18734, 512, 2) (18734, 24) (6405, 512, 2) (6405, 24)\n",
            "1\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 390us/step - loss: 8.5397e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 4.0975e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 332us/step - loss: 8.4673e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 4.1745e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 8.4267e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 4.0593e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 8.3608e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 4.0875e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 8.3107e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.9784e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 8.2421e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.9940e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 8.2250e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.9725e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 8.1475e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.7599e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 331us/step - loss: 8.1181e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.9335e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 8.0209e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.7049e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 156us/step\n",
            "[0.0017253403966999532, 0.9747072599531615, 0.9745040339664218]\n",
            "2\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 392us/step - loss: 8.0137e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.7647e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 7.9505e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.8195e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 7.8796e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.8495e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 7.8768e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.6913e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 7.8009e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.6559e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 7.7452e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.7149e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 7.7111e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.6417e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 7.6761e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.6799e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 7.6240e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.6050e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 7.5992e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.6169e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 154us/step\n",
            "[0.001681784788174163, 0.9756440281030445, 0.9754408021163047]\n",
            "3\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 389us/step - loss: 7.5368e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.6531e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 7.4915e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.5306e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 7.4575e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.4728e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 7.3647e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.5976e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 7.3760e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.6120e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 357us/step - loss: 7.3533e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.4864e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 5s 364us/step - loss: 7.2958e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.4237e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 5s 364us/step - loss: 7.2700e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.3710e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 351us/step - loss: 7.2186e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.3752e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 332us/step - loss: 7.1803e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.3609e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 160us/step\n",
            "[0.0016971701396647158, 0.975487900078064, 0.9752846740913242]\n",
            "4\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 394us/step - loss: 7.1327e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.2820e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 7.1087e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.3444e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 7.0564e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.3373e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 7.0202e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.1845e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 6.9908e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.2219e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 6.9249e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.3122e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 6.9239e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.2881e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 6.9024e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.2611e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 6.8383e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.1107e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 6.8159e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.0923e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 159us/step\n",
            "[0.0016997652381257554, 0.975487900078064, 0.9752846740913242]\n",
            "5\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 394us/step - loss: 6.7783e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.1793e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 6.7517e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.1488e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 6.7150e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.0996e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 6.6795e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.1369e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 6.6451e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.1242e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 6.6211e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.0677e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 6.5818e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.1097e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 6.5565e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 3.0593e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 6.5093e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.9267e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 6.4923e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.9727e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 155us/step\n",
            "[0.001683502599759144, 0.9756440281030445, 0.9754408021163047]\n",
            "6\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 400us/step - loss: 6.4658e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.9883e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 6.4286e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.9835e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 325us/step - loss: 6.3988e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.9106e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 330us/step - loss: 6.3612e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.8773e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 6.3429e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.8400e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 6.3090e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.8241e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 326us/step - loss: 6.2698e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.7786e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 6.2501e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.8746e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 6.2206e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.7933e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 333us/step - loss: 6.2017e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.8277e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 161us/step\n",
            "[0.0016871785350307774, 0.9756440281030445, 0.9754408021163047]\n",
            "7\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 406us/step - loss: 6.1668e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.8361e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 332us/step - loss: 6.1407e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.8460e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 6.1119e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.7682e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 333us/step - loss: 6.0885e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.7797e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 333us/step - loss: 6.0636e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.7226e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 327us/step - loss: 6.0026e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.8291e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 328us/step - loss: 5.9973e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.7051e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 330us/step - loss: 5.9772e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.7484e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 337us/step - loss: 5.9551e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.6654e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 336us/step - loss: 5.9293e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.7147e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 160us/step\n",
            "[0.0016826766439690629, 0.9756440281030445, 0.9754408021163047]\n",
            "8\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 417us/step - loss: 5.8972e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.6215e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 334us/step - loss: 5.8800e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.6201e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 334us/step - loss: 5.8608e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.6358e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 334us/step - loss: 5.8138e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.5608e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 335us/step - loss: 5.8081e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.6308e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 333us/step - loss: 5.7883e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.6110e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 333us/step - loss: 5.7629e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.5866e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 333us/step - loss: 5.7345e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.6004e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 332us/step - loss: 5.7102e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.5620e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 329us/step - loss: 5.6933e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.5494e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 158us/step\n",
            "[0.0016918383858015274, 0.9756440281030445, 0.9754408021163047]\n",
            "9\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 411us/step - loss: 5.6680e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.6103e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 331us/step - loss: 5.6513e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.5630e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 335us/step - loss: 5.6157e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.4927e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 335us/step - loss: 5.6025e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.4783e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 345us/step - loss: 5.5773e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.5379e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 352us/step - loss: 5.5538e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.5147e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 4s 348us/step - loss: 5.5372e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.4659e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 4s 344us/step - loss: 5.5044e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.5043e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 4s 340us/step - loss: 5.4713e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3886e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 343us/step - loss: 5.4687e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3943e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 166us/step\n",
            "[0.0016920925604511916, 0.9756440281030445, 0.9754408021163047]\n",
            "10\n",
            "Train on 12551 samples, validate on 6183 samples\n",
            "Epoch 1/10\n",
            "12551/12551 [==============================] - 5s 431us/step - loss: 5.4453e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.4255e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 2/10\n",
            "12551/12551 [==============================] - 4s 342us/step - loss: 5.4175e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3636e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 3/10\n",
            "12551/12551 [==============================] - 4s 337us/step - loss: 5.3991e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.4355e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 4/10\n",
            "12551/12551 [==============================] - 4s 337us/step - loss: 5.3877e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.4376e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 5/10\n",
            "12551/12551 [==============================] - 4s 343us/step - loss: 5.3599e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.4537e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 6/10\n",
            "12551/12551 [==============================] - 4s 355us/step - loss: 5.3421e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3637e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 7/10\n",
            "12551/12551 [==============================] - 5s 364us/step - loss: 5.3220e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3929e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 8/10\n",
            "12551/12551 [==============================] - 5s 366us/step - loss: 5.3088e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3650e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 9/10\n",
            "12551/12551 [==============================] - 5s 360us/step - loss: 5.2854e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3018e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "Epoch 10/10\n",
            "12551/12551 [==============================] - 4s 348us/step - loss: 5.2674e-11 - acc: 1.0000 - f1_score_macro: 1.0000 - val_loss: 2.3061e-09 - val_acc: 1.0000 - val_f1_score_macro: 1.0000\n",
            "6405/6405 [==============================] - 1s 164us/step\n",
            "[0.0016971528283432993, 0.9756440281030445, 0.9754408021163047]\n",
            "[[0.00172534 0.97470726 0.97450403]\n",
            " [0.00168178 0.97564403 0.9754408 ]\n",
            " [0.00169717 0.9754879  0.97528467]\n",
            " [0.00169977 0.9754879  0.97528467]\n",
            " [0.0016835  0.97564403 0.9754408 ]\n",
            " [0.00168718 0.97564403 0.9754408 ]\n",
            " [0.00168268 0.97564403 0.9754408 ]\n",
            " [0.00169184 0.97564403 0.9754408 ]\n",
            " [0.00169209 0.97564403 0.9754408 ]\n",
            " [0.00169715 0.97564403 0.9754408 ]]\n",
            "[0.00169385 0.97551913 0.9753159 ] [1.21560383e-05 2.77539248e-04 2.77539248e-04]\n",
            "[[4.54325237e-03 9.32557747e-01 9.31203482e-01]\n",
            " [3.79281264e-03 9.42505480e-01 9.42429327e-01]\n",
            " [3.75008726e-03 9.43854325e-01 9.43476957e-01]\n",
            " [3.69617167e-03 9.45034564e-01 9.44836006e-01]\n",
            " [3.58518459e-03 9.46214804e-01 9.46365143e-01]\n",
            " [3.54806897e-03 9.47226437e-01 9.46760283e-01]\n",
            " [3.55819177e-03 9.47395043e-01 9.47215332e-01]\n",
            " [3.54723174e-03 9.47732254e-01 9.47325227e-01]\n",
            " [3.53468320e-03 9.47563649e-01 9.47465943e-01]\n",
            " [3.48127895e-03 9.48069466e-01 9.48077924e-01]\n",
            " [6.49606578e-05 9.99062500e-01 9.99050098e-01]\n",
            " [6.36307355e-05 9.99218750e-01 9.99139384e-01]\n",
            " [6.42838953e-05 9.99218750e-01 9.99206349e-01]\n",
            " [6.49321417e-05 9.99218750e-01 9.99139384e-01]\n",
            " [6.39273519e-05 9.99218750e-01 9.99218750e-01]\n",
            " [6.34789354e-05 9.99218750e-01 9.99218750e-01]\n",
            " [6.30889613e-05 9.99218750e-01 9.99218750e-01]\n",
            " [6.43785134e-05 9.99218750e-01 9.99218750e-01]\n",
            " [6.37578996e-05 9.99218750e-01 9.99218750e-01]\n",
            " [6.44740318e-05 9.99218750e-01 9.99218750e-01]\n",
            " [3.27336321e-08 1.00000000e+00 1.00000000e+00]\n",
            " [1.58461154e-08 1.00000000e+00 1.00000000e+00]\n",
            " [1.11536588e-08 1.00000000e+00 1.00000000e+00]\n",
            " [8.71534155e-09 1.00000000e+00 1.00000000e+00]\n",
            " [7.07382405e-09 1.00000000e+00 1.00000000e+00]\n",
            " [6.03466212e-09 1.00000000e+00 1.00000000e+00]\n",
            " [5.43199411e-09 1.00000000e+00 1.00000000e+00]\n",
            " [4.89476753e-09 1.00000000e+00 1.00000000e+00]\n",
            " [4.47871447e-09 1.00000000e+00 1.00000000e+00]\n",
            " [4.06414451e-09 1.00000000e+00 1.00000000e+00]\n",
            " [1.72534040e-03 9.74707260e-01 9.74504034e-01]\n",
            " [1.68178479e-03 9.75644028e-01 9.75440802e-01]\n",
            " [1.69717014e-03 9.75487900e-01 9.75284674e-01]\n",
            " [1.69976524e-03 9.75487900e-01 9.75284674e-01]\n",
            " [1.68350260e-03 9.75644028e-01 9.75440802e-01]\n",
            " [1.68717854e-03 9.75644028e-01 9.75440802e-01]\n",
            " [1.68267664e-03 9.75644028e-01 9.75440802e-01]\n",
            " [1.69183839e-03 9.75644028e-01 9.75440802e-01]\n",
            " [1.69209256e-03 9.75644028e-01 9.75440802e-01]\n",
            " [1.69715283e-03 9.75644028e-01 9.75440802e-01]]\n",
            "[0.00136541 0.97988441 0.97975406] [0.00151831 0.0226196  0.02275828]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tv7O1HexF8Ct",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "np.savetxt(\"results.csv\", np.asarray(results), delimiter=\", \", newline=\"\\r\\n\")\n",
        "files.download('results.csv') \n",
        "summary.append(np.mean(results,axis=0))\n",
        "np.savetxt(\"summary.csv\", np.asarray(summary), delimiter=\", \", newline=\"\\r\\n\")\n",
        "files.download('summary.csv') \n",
        "with open('model.txt','w') as fh:\n",
        "    model.summary(print_fn=lambda x: fh.write('#' + x + '\\r\\n'))\n",
        "    fh.write(str(model.get_config()))\n",
        "files.download('model.txt') "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}